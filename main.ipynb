{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T10:20:20.495317Z",
     "start_time": "2019-03-24T10:20:20.491681Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T10:20:24.914252Z",
     "start_time": "2019-03-24T10:20:22.767793Z"
    },
    "code_folding": [
     0.0
    ]
   },
   "outputs": [],
   "source": [
    "# External Lib imports\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "\n",
    "# Torch imports\n",
    "import torch.nn as nn\n",
    "import torch.tensor as tensor\n",
    "import torch.nn.functional as func\n",
    "\n",
    "# Mytorch imports\n",
    "from mytorch import loops as mtlp\n",
    "from mytorch.utils.goodies import *\n",
    "from mytorch import lriters as mtlr\n",
    "\n",
    "# Local imports\n",
    "from data import DataPuller\n",
    "from options import Phase2 as Params\n",
    "\n",
    "os.environ['QT_QPA_PLATFORM'] = 'offscreen'\n",
    "\n",
    "# FastAI Imports\n",
    "from fastai import text, core, lm_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T10:20:42.833584Z",
     "start_time": "2019-03-24T10:20:42.824664Z"
    }
   },
   "outputs": [],
   "source": [
    "QUICK = False\n",
    "DEBUG = True\n",
    "PRETRAINED = True\n",
    "MESSAGE = \"A new start\"\n",
    "SAFE_MODE = True\n",
    "DATASETS = \"imdb,wikitext\".split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     17.0,
     22.0,
     87.0,
     92.0,
     101.0
    ]
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:2'\n",
    "KNOWN_DATASETS = ['imdb', 'wikitext']\n",
    "\n",
    "device = torch.device(DEVICE)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Path fields\n",
    "PATH = Path('resources/proc/imdb')\n",
    "DATA_PROC_PATH = PATH / 'data'\n",
    "DATA_LM_PATH = PATH / 'datalm'\n",
    "DUMP_PATH = Path('resources/models/runs')\n",
    "\n",
    "LM_PATH = Path('resources/models')\n",
    "LM_PATH.mkdir(exist_ok=True)\n",
    "PRE_PATH = LM_PATH / 'wt103'\n",
    "PRE_LM_PATH = PRE_PATH / 'fwd_wt103.h5'\n",
    "\n",
    "'''\n",
    "    Data sampler for this training\n",
    "'''\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "class DomainAgnosticSampler:\n",
    "    \"\"\" Sample data for language model training from two different domains in one batch. \"\"\"\n",
    "\n",
    "    def __init__(self, data_fn, data_a, data_b):\n",
    "        \"\"\"\n",
    "            Here, data_fn would be something like\n",
    "                `partial(text.LanguageModelLoader, bs=bs, bptt=bptt)`\n",
    "            And data_a/b would be something like\n",
    "                `{'train': np.concatenate(trn_lm), 'valid': np.concatenate(val_lm)}['train']`\n",
    "            data_fn (fastai's language model loader) flattens y and returns x of seqlen, batchsize\n",
    "        \"\"\"\n",
    "        self.args = {'data_fn': data_fn, 'data_a': data_a, 'data_b': data_b}\n",
    "        self.reset(**self.args)\n",
    "        self.itera, self.iterb = iter([]), iter([])\n",
    "\n",
    "    def reset(self, data_fn, data_a, data_b):\n",
    "        self.itera = iter(data_fn(data_a))\n",
    "        self.iterb = iter(data_fn(data_b))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        x_a, y_a = self.itera.__next__()\n",
    "        x_b, y_b = self.iterb.__next__()\n",
    "        return self._combine_batch_(x_a, x_b, y_a, y_b)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.args['data_fn'](self.args['data_a'])),\n",
    "                   len(self.args['data_fn'](self.args['data_b'])))\n",
    "\n",
    "    @staticmethod\n",
    "    def _combine_batch_(x_a, x_b, y_a, y_b):\n",
    "        \"\"\"\n",
    "            :param x_a is a np.arr looks like seqlen, batchsize\n",
    "            :param y_a is a corresponding np.arr (one word ahead than x_a) which is a flattened x_a.shape mat\n",
    "             Same for x_b, y_b\n",
    "\n",
    "             Returns x, y, y_dom in similar shapes as input\n",
    "        \"\"\"\n",
    "\n",
    "        # Get them to interpretable shapes\n",
    "        y_a = y_a.reshape(x_a.shape).transpose(1, 0)\n",
    "        y_b = y_b.reshape(x_b.shape).transpose(1, 0)\n",
    "        x_a = x_a.transpose(1, 0)\n",
    "        x_b = x_b.transpose(1, 0)\n",
    "\n",
    "        b_bs, b_sl = x_a.shape[0], min(x_a.shape[1], x_b.shape[1])\n",
    "\n",
    "        # Concatenate to make an x and y\n",
    "        x = np.concatenate((x_a[:, :b_sl], x_b[:, :b_sl]))\n",
    "        y = np.concatenate((y_a[:, :b_sl], y_b[:, :b_sl]))\n",
    "\n",
    "        # Shuffle and remember shuffle index to make y labels for domain agnostic training\n",
    "        intrp = np.arange(b_bs * 2)\n",
    "        np.random.shuffle(intrp)\n",
    "        y_dom = (intrp >= b_bs) * 1\n",
    "        x = x[intrp]\n",
    "        y = y[intrp]\n",
    "\n",
    "        x = x.transpose(1, 0)\n",
    "        y = y.transpose(1, 0).reshape(np.prod(y.shape))\n",
    "\n",
    "        return x, y, y_dom\n",
    "\n",
    "\n",
    "'''\n",
    "    Model definitions\n",
    "'''\n",
    "\n",
    "\n",
    "class CustomEncoder(lm_rnn.RNN_Encoder):\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return torch.nn.ModuleList([torch.nn.ModuleList([self.rnns[0], self.dropouths[0]]),\n",
    "                                    torch.nn.ModuleList([self.rnns[1], self.dropouths[1]]),\n",
    "                                    torch.nn.ModuleList([self.rnns[2], self.dropouths[2]])])\n",
    "\n",
    "\n",
    "class CustomDecoder(text.LinearDecoder):\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return torch.nn.ModuleList([self.decoder, self.dropout])\n",
    "\n",
    "    def forward(self, x):\n",
    "        raw_outputs, outputs = x\n",
    "        output = self.dropout(outputs[-1])\n",
    "        decoded = self.decoder(output.view(output.size(0) * output.size(1), output.size(2)))\n",
    "        result = decoded.view(-1, decoded.size(1))\n",
    "        return result, raw_outputs, outputs\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "class CustomLinear(lm_rnn.PoolingLinearClassifier):\n",
    "\n",
    "    def forward(self, x):\n",
    "        raw_outputs, outputs = x\n",
    "        output = outputs[-1]\n",
    "        sl,bs,_ = output.size()\n",
    "        avgpool = self.pool(output, bs, False)\n",
    "        mxpool = self.pool(output, bs, True)\n",
    "        x = torch.cat([output[-1], mxpool, avgpool], 1)\n",
    "        for i, l in enumerate(self.layers):\n",
    "            l_x = l(x)\n",
    "            if i != len(self.layers) -1:\n",
    "                x = func.relu(l_x)\n",
    "            else:\n",
    "                x = torch.sigmoid(l_x)\n",
    "        return l_x, raw_outputs, outputs\n",
    "\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 _parameter_dict,\n",
    "                 _device,\n",
    "                 _encargs,\n",
    "                 _wgts_e=None,\n",
    "                 _wgts_d=None):\n",
    "        super(LanguageModel, self).__init__()\n",
    "\n",
    "        self.parameter_dict = _parameter_dict\n",
    "        self.device = _device\n",
    "\n",
    "        self.encoder = CustomEncoder(**_encargs).to(self.device)\n",
    "        if _wgts_e:\n",
    "            self.encoder.load_state_dict(_wgts_e)\n",
    "        \"\"\"\n",
    "            Explanation:\n",
    "                400*3 because input is [ h_T, maxpool, meanpool ]\n",
    "                0.4, 0.1 are drops at various layersLM_PATH\n",
    "        \"\"\"\n",
    "        self.linear_dec = CustomDecoder(\n",
    "            _encargs['ntoken'],\n",
    "            n_hid=400,\n",
    "            dropout=Params.decoder_drops,\n",
    "            tie_encoder=self.encoder.encoder,\n",
    "            bias=False\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.linear_dom = CustomLinear(layers=Params.domclas_layers, drops=Params.domclas_drops).to(self.device)\n",
    "        self.encoder.reset()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_enc = self.encoder(x)\n",
    "        return self.linear_dec(x_enc)\n",
    "\n",
    "    def domain(self, x_enc):\n",
    "        x_enc = list(x_enc)\n",
    "        x_enc[1] = [GradReverse.apply(enc_tensr) for enc_tensr in x_enc[1]]\n",
    "        return self.linear_dom(x_enc)[0]\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return self.encoder.layers.extend(self.linear_dec.layers).extend(self.linear_dom.layers)\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            self.eval()\n",
    "            pred = self.forward(x)\n",
    "            self.train()\n",
    "            return pred\n",
    "\n",
    "\n",
    "def _eval(y_pred, y_true):\n",
    "    \"\"\"\n",
    "        Expects a batch of input\n",
    "\n",
    "        :param y_pred: tensor of shape (b, nc)\n",
    "        :param y_true: tensor of shape (b, 1)\n",
    "    \"\"\"\n",
    "    return torch.mean((torch.argmax(y_pred, dim=1) == y_true).float())\n",
    "\n",
    "\n",
    "'''\n",
    "    Training loop\n",
    "    \n",
    "        - sample from wiki\n",
    "            - e(x_w)        forward from encoder\n",
    "            - d(e(x_w))     forward from decoder\n",
    "            - backward normally\n",
    "            \n",
    "            - e(x_w)'       grad reverse layer\n",
    "            - d'(e(x_w)')   forward from domain agnostic layer\n",
    "            - backward\n",
    "            \n",
    "        - sample from imdb\n",
    "            - same...\n",
    "'''\n",
    "\n",
    "\n",
    "# noinspection PyShadowingNames\n",
    "def generic_loop(epochs: int,\n",
    "                 device: torch.device,\n",
    "                 opt: torch.optim,\n",
    "                 loss_main_fn: torch.nn,\n",
    "                 loss_aux_fn: torch.nn,\n",
    "                 loss_aux_scale: float,\n",
    "                 model: torch.nn.Module,\n",
    "                 train_fn: Callable,\n",
    "                 train_aux_fn: Callable,\n",
    "                 predict_fn: Callable,\n",
    "                 data_a: dict,\n",
    "                 data_b: dict,\n",
    "                 data_fn: classmethod,\n",
    "                 save_params,\n",
    "                 save_dir: Path = None,\n",
    "                 save_best: bool = False,\n",
    "                 save_above_trn: float = -np.inf,\n",
    "                 save_above_aux: float = np.inf,\n",
    "                 epoch_count: int = 0,\n",
    "                 epoch_start_hook: Callable = None,\n",
    "                 epoch_end_hook: Callable = None,\n",
    "                 batch_start_hook: Callable = None,\n",
    "                 batch_end_hook: Callable = None,\n",
    "                 weight_decay: float = Params.weight_decay,\n",
    "                 clip_grads_at: float = Params.clip_grads_at,\n",
    "                 lr_schedule = None,\n",
    "                 eval_fn: Callable = None,\n",
    "                 eval_aux_fn: Callable = None,\n",
    "                 notify: bool = False,\n",
    "                 notify_key: str = None) -> (list, list, list):\n",
    "    \"\"\"\n",
    "\n",
    "        A generic training loop, which based on diff hook fns (defined below), should handle anything given to it.\n",
    "\n",
    "        The model need not be an nn.Module,\n",
    "             but should have correctly wired forward and a predict function.\n",
    "\n",
    "        # Data input\n",
    "            Data should be a dict like so:\n",
    "                {\"train\":{\"x\":np.arr, \"y\":np.arr}, \"val\":{\"x\":np.arr, \"y\":np.arr} }\n",
    "\n",
    "            Train_fn must return both loss and y_pred\n",
    "\n",
    "        # Saving Logic\n",
    "            There are two conditions on which it saves models (named differently).\n",
    "            1. Highest train accuracy\n",
    "            2. Lowest auxiliary accuracy (which is empirically seen to stabilize after two epochs) after two epochs have passed\n",
    "\n",
    "    :param epochs: number of epochs to train for\n",
    "    :param data_a: data dict (structure specified above) (main)\n",
    "    :param data_b: data dict (structure specified above) (aux)\n",
    "    :param device: torch device to init the tensors with\n",
    "    :param opt: torch optimizer, with proper param_groups for better lr decay per laye\n",
    "    :param loss_main_fn: torch.nn loss fn for the actual thing\n",
    "    :param loss_aux_fn: torch.nn loss fn for the domain agnostic thing\n",
    "    :param loss_aux_scale: float signifying how much to scale DANN loss with, while combining losses.\n",
    "    :param model: torch module (for grad clipping)\n",
    "    :param train_fn: a function which takes x & y, returns loss and y_pred\n",
    "    :param train_aux_fn: a function which takes x & y, returns loss and y_pred_aux\n",
    "    :param predict_fn: a fn which takes x and returns y_pred\n",
    "    :param epoch_count: an int which is added with #epochs (for better representation of how many epochs have actually passed)\n",
    "            You can use this for when you run the loop say 3 times, do something else and run it for another 10.\n",
    "    :param epoch_start_hook: a fn that can be called @ start of every epoch (returns model, opt)\n",
    "    :param epoch_end_hook: a fn that can be called @ end of every epoch (returns model, opt)\n",
    "    :param batch_start_hook: a fn that can be called @ start of every batch (returns model, opt)\n",
    "    :param batch_end_hook: a fn that can be called @r end of every batch (returns model, opt)\n",
    "    :param weight_decay: a L2 ratio (as mentioned in (https://arxiv.org/pdf/1711.05101.pdf)\n",
    "    :param clip_grads_at: in case you want gradients clipped, send the max val here\n",
    "    :param lr_schedule: a schedule that is called @ every batch start.\n",
    "    :param save_best: bool which wants either doesn't save, or saves at best\n",
    "    :param save_dir: Path object to which we save stuff (based on save_best)\n",
    "    :param save_params: a dict of all the params used while running and training the model.\n",
    "    :param save_above_trn: [OPTIONAL] acts as threshold regarading model saving. If the current trn accuracy is less than this, won't.\n",
    "    :param save_above_aux: [OPTIONAL] acts as threshold regarading model saving. If the current aux accuracy is more than this, won't.\n",
    "    :param data_fn: a class to which we can pass X and Y, and get an iterator.\n",
    "    :param eval_fn: function which when given pred and true, returns acc\n",
    "    :param eval_aux_fn: same as eval_fn but for domain classifier's output.\n",
    "    :param notify: (optional) flag which enables sending notifications to your phones once the loop is done.\n",
    "    :param notify_key: (optional) the api key to which the notification is to be sent. You can give it here, or in a file (see README.md)\n",
    "    :return: traces\n",
    "    \"\"\"\n",
    "\n",
    "    train_loss_main = []\n",
    "    train_loss_aux = []\n",
    "    train_acc_main = []\n",
    "    train_acc_aux = []\n",
    "    val_acc = []\n",
    "    lrs = []\n",
    "    saved_info = {}\n",
    "\n",
    "    assert (not save_best) or (save_best and save_dir), \"No save dir specified.\"\n",
    "\n",
    "    # Epoch level\n",
    "    for e in range(epoch_count, epochs+epoch_count):\n",
    "\n",
    "        per_epoch_loss_main = []\n",
    "        per_epoch_loss_aux = []\n",
    "        per_epoch_tr_acc_main = []\n",
    "        per_epoch_tr_acc_aux = []\n",
    "\n",
    "        # Train\n",
    "        with Timer() as timer:\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            # @TODO: Add hook at start of epoch (how to decide what goes in)\n",
    "            if epoch_start_hook: epoch_start_hook()\n",
    "\n",
    "            # Make data\n",
    "            trn_dl = data_fn(data_a=data_a['train'], data_b=data_b['train'])\n",
    "            val_dl = data_fn(data_a=data_a['valid'], data_b=data_b['valid'])\n",
    "\n",
    "            for x, y, y_aux in tqdm(trn_dl):\n",
    "\n",
    "                if batch_start_hook:\n",
    "                    batch_start_hook()\n",
    "\n",
    "                opt.zero_grad()\n",
    "\n",
    "                if lr_schedule: lrs.append(update_lr(opt, lr_schedule.get()))\n",
    "\n",
    "                # 0. Convert np arrs to torch tensors\n",
    "                _x = torch.tensor(x, dtype=torch.long, device=device)\n",
    "                _y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "                _y_aux = torch.tensor(y_aux, dtype=torch.long, device=device)\n",
    "\n",
    "                # A: Normal stuff\n",
    "                op = train_fn(_x)\n",
    "                y_pred = op[0]\n",
    "                loss_main = loss_main_fn(y_pred, _y)\n",
    "\n",
    "                # B: Domain agnostic stuff\n",
    "                y_pred_aux = train_aux_fn(op[1:])\n",
    "                loss_aux = loss_aux_fn(y_pred_aux, _y_aux)\n",
    "\n",
    "                # C. Add losses with scale.\n",
    "                loss = loss_main + (loss_aux_scale * loss_aux)\n",
    "\n",
    "                # Logging\n",
    "                per_epoch_tr_acc_main.append(eval_fn(y_pred=y_pred, y_true=_y).item())\n",
    "                per_epoch_tr_acc_aux.append(eval_aux_fn(y_pred=y_pred_aux, y_true=_y_aux).item())\n",
    "                per_epoch_loss_main.append(loss_main.item())\n",
    "                per_epoch_loss_aux.append(loss_aux.item())\n",
    "\n",
    "                # Pass aux gradients\n",
    "                loss.backward(retain_graph=False)\n",
    "\n",
    "                # Optimizer Step\n",
    "                if clip_grads_at > 0.0: torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grads_at)\n",
    "                for group in opt.param_groups:\n",
    "                    for param in group['params']:\n",
    "                        param.data = param.data.add(-weight_decay * group['lr'], param.data)\n",
    "\n",
    "                opt.step()\n",
    "                if batch_end_hook:\n",
    "                    batch_end_hook()\n",
    "\n",
    "            if epoch_end_hook:\n",
    "                epoch_end_hook()\n",
    "\n",
    "        # Val\n",
    "        with torch.no_grad():\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            per_epoch_vl_acc = []\n",
    "            for x, y, y_aux in tqdm(val_dl):\n",
    "                _x = torch.tensor(x, dtype=torch.long, device=device)\n",
    "                _y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "\n",
    "                y_pred = predict_fn(_x)[0]\n",
    "\n",
    "                per_epoch_vl_acc.append(eval_fn(y_pred, _y).item())\n",
    "\n",
    "        # Bookkeep\n",
    "        train_acc_main.append(np.mean(per_epoch_tr_acc_main))\n",
    "        train_acc_aux.append(np.mean(per_epoch_tr_acc_aux))\n",
    "        train_loss_main.append(np.mean(per_epoch_loss_main))\n",
    "        train_loss_aux.append(np.mean(per_epoch_loss_main))\n",
    "        val_acc.append(np.mean(per_epoch_vl_acc))\n",
    "\n",
    "        print(\"Epoch: %(epo)03d | \"\n",
    "              \"Loss: %(loss).4f | \"\n",
    "              \"Loss_aux: %(loss_aux).4f | \"\n",
    "              \"Tr_c: %(tracc)0.4f | \"\n",
    "              \"Vl_c: %(vlacc)0.5f | \"\n",
    "              \"Tr_aux: %(tracc_aux)0.4f | \"\n",
    "              \" Time: %(time).3f m\"\n",
    "              % {'epo': e+epoch_count,\n",
    "                 'loss': float(np.mean(per_epoch_loss_main)),\n",
    "                 'loss_aux': float(np.mean(per_epoch_loss_aux)),\n",
    "                 'tracc': float(np.mean(per_epoch_tr_acc_main)),\n",
    "                 'tracc_aux': float(np.mean(per_epoch_tr_acc_aux)),\n",
    "                 'vlacc': float(np.mean(per_epoch_vl_acc)),\n",
    "                 'time': timer.interval / 60.0})\n",
    "\n",
    "        # Save block (flag and condition)\n",
    "        if save_best and train_acc_main[-1] >= save_above_trn:\n",
    "\n",
    "            # Update threshold\n",
    "            save_above_trn = train_acc_main[-1]\n",
    "\n",
    "            # Adding epoch info along with options\n",
    "            save_params.epoch = e\n",
    "\n",
    "            # Call save function and save\n",
    "            mt_save(save_dir,\n",
    "                    torch_stuff=[tosave('unsup_model_hightrn.torch', model.state_dict()),\n",
    "                                 tosave('unsup_model_enc_hightrn.torch', model.encoder.state_dict())],\n",
    "                    pickle_stuff=[tosave('unsup_traces.pkl', [train_acc_main, val_acc, train_acc_aux, train_loss_main, train_loss_aux, lrs]),\n",
    "                                  tosave('unsup_options.pkl', save_params)])\n",
    "            print(f\"Model saved on Epoch {e} at {save_dir} because of highest training acc so far\")\n",
    "\n",
    "            # Log the saved thing\n",
    "            saved_info['epoch'] = e\n",
    "            saved_info['accuracy'] = val_acc[-1]\n",
    "            saved_info['directory'] = save_dir\n",
    "\n",
    "        # Save block (flag and condition) (When more than 2 epochs have pased and we see lowest aux accuracy)\n",
    "        if save_best and e > 1 and train_acc_aux[-1] <= save_above_aux:\n",
    "\n",
    "            # Update threshold\n",
    "            save_above_aux = train_acc_aux[-1]\n",
    "\n",
    "            # Adding epoch info along with options\n",
    "            save_params.epoch = e\n",
    "\n",
    "            # Call save function and save\n",
    "            mt_save(save_dir,\n",
    "                    torch_stuff=[tosave('unsup_model_lowaux.torch', model.state_dict()),\n",
    "                                 tosave('unsup_model_enc_lowaux.torch', model.encoder.state_dict())],\n",
    "                    pickle_stuff=[\n",
    "                        tosave('unsup_traces.pkl', [train_acc_main, val_acc, train_acc_aux, train_loss_main, train_loss_aux, lrs]),\n",
    "                        tosave('unsup_options.pkl', save_params)])\n",
    "            print(f\"Model saved on Epoch {e} at {save_dir} because of lowest auxiliary accuracy so far\")\n",
    "\n",
    "            # Log the saved thing\n",
    "            saved_info['epoch'] = e\n",
    "            saved_info['accuracy'] = val_acc[-1]\n",
    "            saved_info['directory'] = save_dir\n",
    "\n",
    "    if notify:\n",
    "        if not saved_info:\n",
    "            message_template = \"Your model is done training.\"\n",
    "            send_notification(data=saved_info, key=notify_key, message_template=message_template)\n",
    "        else:\n",
    "            send_notification(data=saved_info, key=notify_key)\n",
    "\n",
    "    return train_acc_main, val_acc, train_acc_aux, train_loss_main, train_loss_aux, lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check args.\n",
    "for dataset in DATASETS:\n",
    "    assert dataset in KNOWN_DATASETS, f\"Couldn't find a dataset called {dataset}. Exiting.\"\n",
    "\n",
    "Params.message = MESSAGE\n",
    "Params.quick = QUICK\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"Pulling data from disk\")\n",
    "\n",
    "# Pulling data from disk\n",
    "data_puller = DataPuller(debug=False, max_vocab=Params.max_vocab_task, min_freq=Params.min_vocab_freq, trim_trn=1000, trim_val=-1)\n",
    "trn_lm, val_lm, _ = data_puller.get('imdb', supervised=False, trim=Params.quick)\n",
    "wiki_trn_lm, wiki_val_lm, itos = data_puller.get('wikitext', supervised=False, trim=Params.quick, merge_vocab=Params.max_vocab_wiki)\n",
    "vs = len(itos)\n",
    "\n",
    "\"\"\"\n",
    "    Now we pull pretrained models from disk    \n",
    "\"\"\"\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"Pulling models from disk\")\n",
    "\n",
    "em_sz, nh, nl = 400, 1150, 3\n",
    "# PRE_PATH = PATH / 'models' / 'wt103'\n",
    "# PRE_LM_PATH = PRE_PATH / 'fwd_wt103.h5'\n",
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)\n",
    "enc_wgts = core.to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)\n",
    "itos2 = pickle.load((PRE_PATH / 'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda: -1, {v: k for k, v in enumerate(itos2)})\n",
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for i, w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r >= 0 else row_m\n",
    "\n",
    "# noinspection PyCallingNonCallable\n",
    "wgts['0.encoder.weight'] = tensor(new_w)\n",
    "# noinspection PyCallingNonCallable\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = tensor(np.copy(new_w))\n",
    "# noinspection PyCallingNonCallable\n",
    "wgts['1.decoder.weight'] = tensor(np.copy(new_w))\n",
    "wgts_enc = {'.'.join(k.split('.')[1:]): val\n",
    "            for k, val in wgts.items() if k[0] == '0'}\n",
    "wgts_dec = {'.'.join(k.split('.')[1:]): val\n",
    "            for k, val in wgts.items() if k[0] == '1'}\n",
    "\n",
    "'''\n",
    "    Setting up things for training.\n",
    "'''\n",
    "bptt = 70\n",
    "bs = Params.bs\n",
    "opt_fn = partial(torch.optim.SGD)  # , betas=params.adam_betas)\n",
    "\n",
    "# Load the pre-trained model\n",
    "parameter_dict = {'itos2': itos2}\n",
    "dps = Params.encoder_drops\n",
    "encargs = {'ntoken': new_w.shape[0],\n",
    "           'emb_sz': 400, 'n_hid': 1150,\n",
    "           'n_layers': 3, 'pad_token': 0,\n",
    "           'qrnn': False, 'dropouti': dps[0],\n",
    "           'wdrop': dps[2], 'dropoute': dps[3], 'dropouth': dps[4]}\n",
    "\n",
    "lm = LanguageModel(parameter_dict, device, _wgts_e=wgts_enc if PRETRAINED else None, _wgts_d=wgts_dec, _encargs=encargs)\n",
    "opt = make_opt(lm, opt_fn, lr=Params.lr.init)\n",
    "loss_main_fn = func.cross_entropy\n",
    "loss_aux_fn = func.cross_entropy\n",
    "\n",
    "# Make data\n",
    "data_fn_unidomain = partial(text.LanguageModelLoader, bs=bs, bptt=bptt)\n",
    "data_imdb = {'train': np.concatenate(trn_lm), 'valid': np.concatenate(val_lm)}\n",
    "data_wiki = {'train': np.concatenate(wiki_trn_lm), 'valid': np.concatenate(wiki_val_lm)}\n",
    "data_fn = partial(DomainAgnosticSampler, data_fn=data_fn_unidomain)\n",
    "\n",
    "# Set up lr and freeze stuff\n",
    "for grp in opt.param_groups:\n",
    "    grp['lr'] = 0.0\n",
    "opt.param_groups[3]['lr'] = Params.lr.init\n",
    "opt.param_groups[4]['lr'] = Params.lr.init\n",
    "\n",
    "# lr_args = {'batches':, 'cycles': 1}\n",
    "lr_args = {'iterations': len(data_fn(data_a=data_wiki['train'], data_b=data_imdb['train'])),\n",
    "           'cut_frac': Params.lr.sltr_cutfrac, 'ratio': Params.lr.sltr_ratio}\n",
    "lr_schedule = mtlr.LearningRateScheduler(optimizer=opt, lr_args=lr_args, lr_iterator=mtlr.SlantedTriangularLR)\n",
    "\n",
    "# Find places to save model\n",
    "save_dir = mt_save_dir(DUMP_PATH / 'models', _newdir=True) if not SAFE_MODE else ''\n",
    "\n",
    "if not SAFE_MODE:\n",
    "    # Start to put permanent things there, like the itos\n",
    "    mt_save(save_dir,\n",
    "            pickle_stuff=[tosave('itos.pkl', itos)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'epochs': 1, 'weight_decay': Params.weight_decay, 'data_a': data_imdb, 'data_b': data_wiki,\n",
    "        'device': device, 'opt': opt, 'loss_main_fn': loss_main_fn, 'loss_aux_fn': loss_aux_fn,\n",
    "        'train_fn': lm, 'train_aux_fn': lm.domain, 'predict_fn': lm.predict, 'data_fn': data_fn, 'model': lm,\n",
    "        'eval_fn': _eval, 'eval_aux_fn': _eval, 'batch_start_hook': partial(mtlp.reset_hidden, lm),\n",
    "        'clip_grads_at': Params.clip_grads_at, 'lr_schedule': lr_schedule, 'loss_aux_scale': Params.loss_scale,\n",
    "        'save_dir': save_dir, 'save_best': not SAFE_MODE, 'save_params': Params}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Actual training\n",
    "'''\n",
    "# print(\"Time taken to get everything so far done\")\n",
    "traces_start = generic_loop(**args)\n",
    "\n",
    "# Now unfreeze all layers and apply discr\n",
    "for grp in opt.param_groups:\n",
    "    grp['lr'] = Params.lr.init\n",
    "\n",
    "lr_dscr = lambda optim, lr, fctr=Params.lr.dscr: [lr / (fctr ** p_grp) for p_grp in range(len(optim.param_groups))[::-1]]\n",
    "update_lr(opt, lr_dscr(opt, Params.lr.init))\n",
    "\n",
    "if DEBUG:\n",
    "    print([x['lr'] for x in opt.param_groups])\n",
    "\n",
    "lr_args = {'iterations': len(data_fn(data_a=data_wiki['train'], data_b=data_imdb['train'])) * 15,\n",
    "           'cut_frac': Params.lr.sltr_cutfrac, 'ratio': Params.lr.sltr_ratio}\n",
    "lr_schedule = mtlr.LearningRateScheduler(optimizer=opt, lr_args=lr_args, lr_iterator=mtlr.SlantedTriangularLR)\n",
    "args['save_above_trn'] = np.max(traces_start[0])\n",
    "# args['save_above_aux'] = np.min(traces_start[2][2:])  # Not updating this var since we ignore the DANN acc of the first few epochs anyway\n",
    "args['lr_schedule'] = lr_schedule\n",
    "args['epochs'] = 15\n",
    "args['epoch_count'] = 1\n",
    "args['notify'] = True\n",
    "\n",
    "traces_main = generic_loop(**args)\n",
    "traces = [a + b for a, b in zip(traces_start, traces_main)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style as pltstyle\n",
    "# import matplotlib.style as style\n",
    "# style.available\n",
    "%pylab inline\n",
    "# pylab.rcParams['figure.figsize'] = (16, 8)\n",
    "\n",
    "\n",
    "def plot_accs(tra, vla, axa, style=None, _savedir=None):\n",
    "    pltstyle.use(style if style else 'seaborn-deep')\n",
    "    fig = plt.figure(figsize = (16,8))\n",
    "    ax = fig.add_axes((0.1, 0.2, 0.8, 0.7))\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "    plt.plot(tra, label=f\"Train Acc\", linewidth=3)\n",
    "    plt.plot(vla, label=f\"Valid Acc\", linewidth=3)\n",
    "    plt.plot(axa, label=f\"Aux Acc\", linewidth=3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    if _savedir:\n",
    "        pltstyle.use(style if style else 'seaborn-deep')\n",
    "        fig = plt.figure(figsize = (16,8))\n",
    "        ax = fig.add_axes((0.1, 0.2, 0.8, 0.7))\n",
    "        ax.spines['right'].set_color('none')\n",
    "        ax.spines['top'].set_color('none')\n",
    "    #     plt.xticks([])\n",
    "    #     plt.yticks([])\n",
    "        plt.plot(tra, label=f\"Train Acc\", linewidth=3)\n",
    "        plt.plot(vla, label=f\"Valid Acc\", linewidth=3)\n",
    "        plt.plot(axa, label=f\"Aux Acc\", linewidth=3)\n",
    "        plt.legend()\n",
    "        print(f\"saving fig at {_savedir}\")\n",
    "        plt.savefig(_savedir)\n",
    "    \n",
    "    \n",
    "def plot(trcs):\n",
    "    layers = len(trcs[0])\n",
    "    for l in range(layers):\n",
    "        plt.plot(trcs[:,l], label=f\"layer {l}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_accs(traces[0], traces[1], traces[2], style='seaborn-poster', _savedir=save_dir/'unsup_acc.png' if not SAFE_MODE else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(np.asarray(traces[-1][100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SAFE_MODE:\n",
    "    mt_save(save_dir,\n",
    "            torch_stuff=[tosave('final_unsup_model.torch', lm.state_dict()),\n",
    "                         tosave('final_unsup_model_enc.torch', lm.encoder.state_dict())],\n",
    "            pickle_stuff=[tosave('final_unsup_traces.pkl', traces), \n",
    "                          tosave('unsup_options.pkl', Params)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_best = np.max(traces[0])\n",
    "trn_best_ = np.argmax(traces[0])\n",
    "val_attrn = traces[1][trn_best_]\n",
    "val_best = np.max(traces[1])\n",
    "val_best_ = np.argmax(traces[1])\n",
    "aux_attrn = traces[2][trn_best_]\n",
    "aux_best = np.min(traces[2][2:])\n",
    "aux_best_ = np.argmin(traces[2][2:])\n",
    "print(f\"Train Best: {trn_best:.4f} at {trn_best_}\\nValid @Trn: {val_attrn:.4f}\\nValid Best: {val_best:.4f} at {val_best_}\\nDomAg @Trn: {aux_attrn:.4f}\\nDomAg Best: {aux_best:.4f} at {aux_best_}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
