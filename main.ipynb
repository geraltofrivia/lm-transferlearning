{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe8bc534f50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# External Lib imports\n",
    "import collections\n",
    "import html\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'\n",
    "\n",
    "# FastAI Imports\n",
    "from fastai import text, core, lm_rnn\n",
    "\n",
    "# Torch imports\n",
    "import torch.nn as nn\n",
    "import torch.tensor as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Mytorch imports\n",
    "from mytorch import loops as mtlp\n",
    "from mytorch.utils.goodies import *\n",
    "from mytorch import lriters as mtlr\n",
    "\n",
    "device = torch.device('cuda')\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "TRIM = True\n",
    "\n",
    "# Path fields\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "WIKI_DATA_PATH = Path('raw/wikitext/wikitext-103/')\n",
    "WIKI_DATA_PATH.mkdir(exist_ok=True)\n",
    "IMDB_DATA_PATH = Path('raw/imdb/aclImdb/')\n",
    "IMDB_DATA_PATH.mkdir(exist_ok=True)\n",
    "PATH = Path('resources/proc/imdb')\n",
    "DATA_PROC_PATH = PATH / 'data'\n",
    "DATA_LM_PATH = PATH / 'datalm'\n",
    "\n",
    "LM_PATH = Path('resources/models')\n",
    "LM_PATH.mkdir(exist_ok=True)\n",
    "PRE_PATH = LM_PATH / 'wt103'\n",
    "PRE_LM_PATH = PRE_PATH / 'fwd_wt103.h5'\n",
    "CLASSES = ['neg', 'pos', 'unsup']\n",
    "WIKI_CLASSES = ['wiki.train.tokens', 'wiki.valid.tokens', 'wiki.test.tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class DomainAgnosticSampler:\n",
    "    \"\"\" Sample data for language model training from two different domains in one batch. \"\"\"\n",
    "\n",
    "    def __init__(self, data_fn, data_a, data_b):\n",
    "        \"\"\"\n",
    "            Here, data_fn would be something like\n",
    "                `partial(text.LanguageModelLoader, bs=bs, bptt=bptt)`\n",
    "            And data_a/b would be something like\n",
    "                `{'train': np.concatenate(trn_lm), 'valid': np.concatenate(val_lm)}['train']`\n",
    "            data_fn (fastai's language model loader) flattens y and returns x of seqlen, batchsize\n",
    "        \"\"\"\n",
    "        self.args = {'data_fn': data_fn, 'data_a': data_a, 'data_b': data_b}\n",
    "        self.reset(**self.args)\n",
    "\n",
    "    def reset(self, data_fn, data_a, data_b):\n",
    "        self.itera = iter(data_fn(data_a))\n",
    "        self.iterb = iter(data_fn(data_b))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        x_a, y_a = self.itera.__next__()\n",
    "        x_b, y_b = self.iterb.__next__()\n",
    "        return self._combine_batch_(x_a, x_b, y_a, y_b)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.args['data_fn'](self.args['data_a'])),\n",
    "                   len(self.args['data_fn'](self.args['data_b'])))\n",
    "\n",
    "    @staticmethod\n",
    "    def _combine_batch_(x_a, x_b, y_a, y_b):\n",
    "        \"\"\"\n",
    "            :param x_a is a np.arr looks like seqlen, batchsize\n",
    "            :param y_a is a corresponding np.arr (one word ahead than x_a) which is a flattened x_a.shape mat\n",
    "             Same for x_b, y_b\n",
    "\n",
    "             Returns x, y, y_dom in similar shapes as input\n",
    "        \"\"\"\n",
    "\n",
    "        # Get them to interpretable shapes\n",
    "        y_a = y_a.reshape(x_a.shape).transpose(1, 0)\n",
    "        y_b = y_b.reshape(x_b.shape).transpose(1, 0)\n",
    "        x_a = x_a.transpose(1, 0)\n",
    "        x_b = x_b.transpose(1, 0)\n",
    "\n",
    "        b_bs, b_sl = x_a.shape[0], min(x_a.shape[1], x_b.shape[1])\n",
    "\n",
    "        # Concatenate to make an x and y\n",
    "        x = np.concatenate((x_a[:, :b_sl], x_b[:, :b_sl]))\n",
    "        y = np.concatenate((y_a[:, :b_sl], y_b[:, :b_sl]))\n",
    "\n",
    "        # Shuffle and remember shuffle index to make y labels for domain agnostic training\n",
    "        intrp = np.arange(b_bs * 2)\n",
    "        np.random.shuffle(intrp)\n",
    "        y_dom = (intrp >= b_bs) * 1\n",
    "        x = x[intrp]\n",
    "        y = y[intrp]\n",
    "\n",
    "        x = x.transpose(1, 0)\n",
    "        y = y.transpose(1, 0).reshape(np.prod(y.shape))\n",
    "\n",
    "        return x, y, y_dom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load **IMDB** data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000 25000\n"
     ]
    }
   ],
   "source": [
    "def get_texts_org(path):\n",
    "    texts, labels = [], []\n",
    "    for idx, label in enumerate(CLASSES):\n",
    "        for fname in (path / label).glob('*.*'):\n",
    "            texts.append(fname.open('r', encoding='utf-8').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts), np.array(labels)\n",
    "\n",
    "trn_texts, trn_labels = get_texts_org(IMDB_DATA_PATH / 'train')\n",
    "val_texts, val_labels = get_texts_org(IMDB_DATA_PATH / 'test')\n",
    "col_names = ['labels', 'text']\n",
    "print(len(trn_texts), len(val_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load **WIKI** data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859955 1841\n"
     ]
    }
   ],
   "source": [
    "def is_valid_sent(x):\n",
    "    x = x.strip()\n",
    "    if len(x) == 0: return False\n",
    "    if x[0] == '=' and x[-1] == '=': return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def wiki_get_texts_org(path):\n",
    "    texts = []\n",
    "    for idx, label in enumerate(WIKI_CLASSES):\n",
    "        with open(path / label, encoding='utf-8') as f:\n",
    "            texts.append([sent.strip() for sent in f.readlines() if is_valid_sent(sent)])\n",
    "    return tuple(texts)\n",
    "\n",
    "\n",
    "wiki_trn_texts, wiki_val_texts, wiki_tst_texts = wiki_get_texts_org(WIKI_DATA_PATH)\n",
    "print(len(wiki_trn_texts), len(wiki_val_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed, trim data to only keep top 1000 things from both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRIM:\n",
    "    trn_texts, val_texts = trn_texts[:1000], val_texts[:1000]\n",
    "    wiki_trn_texts, wiki_val_texts, wiki_tst_texts = wiki_trn_texts[:1000], wiki_val_texts[:1000], wiki_tst_texts[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle data & Make dummy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_idx = np.random.permutation(len(trn_texts))\n",
    "val_idx = np.random.permutation(len(val_texts))\n",
    "\n",
    "trn_texts, trn_labels = trn_texts[trn_idx], trn_labels[trn_idx]\n",
    "val_texts, val_labels = val_texts[val_idx], val_labels[val_idx]\n",
    "\n",
    "np.random.shuffle(wiki_trn_texts)\n",
    "np.random.shuffle(wiki_val_texts)\n",
    "np.random.shuffle(wiki_tst_texts)\n",
    "\n",
    "wiki_trn_labels = [0 for _ in wiki_trn_texts]\n",
    "wiki_val_labels = [0 for _ in wiki_val_texts]\n",
    "wiki_tst_labels = [0 for _ in wiki_val_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe magic & Fixing up text & Splitting into train and Val\n",
    "\n",
    "_note_: We read generously from the valid data. Should do something about it!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     4,
     12,
     22,
     30
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 200\n",
      "Trn: (1800, 1800), Val: (200, 200) \n",
      "2700 300\n",
      "Trn: (2700, 2700), Val: (300, 300) \n"
     ]
    }
   ],
   "source": [
    "chunksize = 24000\n",
    "re1 = re.compile(r'  +')\n",
    "\n",
    "\n",
    "def _fixup_(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n",
    "        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "\n",
    "def _get_texts_(df, n_lbls=1):\n",
    "    labels = df.iloc[:, range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls + 1, len(df.columns)): texts += f' {FLD} {i - n_lbls} ' + df[i].astype(str)\n",
    "    texts = list(texts.apply(_fixup_).values)\n",
    "\n",
    "    tok = text.Tokenizer().proc_all_mp(core.partition_by_cores(texts))\n",
    "    return tok, list(labels)\n",
    "\n",
    "\n",
    "def _simple_apply_fixup_(df):\n",
    "    labels = [0] * df.shape[0]\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df.text\n",
    "    texts = list(texts.apply(_fixup_).values)\n",
    "    tok = text.Tokenizer().proc_all_mp(core.partition_by_cores(texts))\n",
    "    return tok, list(labels)\n",
    "\n",
    "\n",
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = _get_texts_(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels\n",
    "\n",
    "trn_texts, val_texts = sklearn.model_selection.train_test_split(\n",
    "        np.concatenate([trn_texts, val_texts]), test_size=0.1)\n",
    "\n",
    "if DEBUG:\n",
    "    print(len(trn_texts), len(val_texts))\n",
    "\n",
    "df_trn = pd.DataFrame({'text': trn_texts, 'labels': [0] * len(trn_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text': val_texts, 'labels': [0] * len(val_texts)}, columns=col_names)\n",
    "\n",
    "trn_tok, trn_labels = _simple_apply_fixup_(df_trn)\n",
    "val_tok, val_labels = _simple_apply_fixup_(df_val)\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"Trn: {len(trn_tok), len(trn_labels)}, Val: {len(val_tok), len(val_labels)} \")\n",
    "\n",
    "wiki_trn_texts, wiki_val_texts = sklearn.model_selection.train_test_split(\n",
    "    np.concatenate([wiki_trn_texts, wiki_val_texts, wiki_tst_texts]), test_size=0.1)\n",
    "\n",
    "if DEBUG:\n",
    "    print(len(wiki_trn_texts), len(wiki_val_texts))\n",
    "\n",
    "wiki_df_trn = pd.DataFrame({'text': wiki_trn_texts, 'labels': [0] * len(wiki_trn_texts)}, columns=col_names)\n",
    "wiki_df_val = pd.DataFrame({'text': wiki_val_texts, 'labels': [0] * len(wiki_val_texts)}, columns=col_names)\n",
    "\n",
    "wiki_trn_tok, wiki_trn_labels = _simple_apply_fixup_(wiki_df_trn)\n",
    "wiki_val_tok, wiki_val_labels = _simple_apply_fixup_(wiki_df_val)\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"Trn: {len(wiki_trn_tok), len(wiki_trn_labels)}, Val: {len(wiki_val_tok), len(wiki_val_labels)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we make vocabulary, select 60k most freq words \n",
    " \n",
    " _note_: we do this looking only at imdb, and ignore wiki here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITOS: 9314, STOI: 25161\n",
      "ITOS: 9314, STOI: 36993\n"
     ]
    }
   ],
   "source": [
    "freq = Counter(p for o in trn_tok for p in o)\n",
    "# freq.most_common(25)\n",
    "max_vocab = 60000\n",
    "min_freq = 2\n",
    "\n",
    "itos = [o for o, c in freq.most_common(max_vocab) if c > min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "stoi = collections.defaultdict(lambda: 0, {v: k for k, v in enumerate(itos)})\n",
    "vs = len(itos)\n",
    "\n",
    "trn_lm = np.array([[stoi[o] for o in p] for p in trn_tok])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in val_tok])\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"ITOS: {len(itos)}, STOI: {len(stoi)}\")\n",
    "\n",
    "wiki_trn_lm = np.array([[stoi[o] for o in p] for p in wiki_trn_tok])\n",
    "wiki_val_lm = np.array([[stoi[o] for o in p] for p in wiki_val_tok])\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"ITOS: {len(itos)}, STOI: {len(stoi)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pull pretrained models from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz, nh, nl = 400, 1150, 3\n",
    "# PRE_PATH = PATH / 'models' / 'wt103'\n",
    "# PRE_LM_PATH = PRE_PATH / 'fwd_wt103.h5'\n",
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)\n",
    "enc_wgts = core.to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)\n",
    "itos2 = pickle.load((PRE_PATH / 'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda: -1, {v: k for k, v in enumerate(itos2)})\n",
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for i, w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r >= 0 else row_m\n",
    "\n",
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))\n",
    "wgts_enc = {'.'.join(k.split('.')[1:]): val\n",
    "            for k, val in wgts.items() if k[0] == '0'}\n",
    "wgts_dec = {'.'.join(k.split('.')[1:]): val\n",
    "            for k, val in wgts.items() if k[0] == '1'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0,
     9,
     41
    ]
   },
   "outputs": [],
   "source": [
    "class CustomEncoder(lm_rnn.RNN_Encoder):\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return torch.nn.ModuleList([torch.nn.ModuleList([self.rnns[0], self.dropouths[0]]),\n",
    "                                    torch.nn.ModuleList([self.rnns[1], self.dropouths[1]]),\n",
    "                                    torch.nn.ModuleList([self.rnns[2], self.dropouths[2]])])\n",
    "\n",
    "\n",
    "class CustomDecoder(text.LinearDecoder):\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return torch.nn.ModuleList([self.decoder, self.dropout])\n",
    "\n",
    "    def forward(self, input):\n",
    "        raw_outputs, outputs = input\n",
    "        output = self.dropout(outputs[-1])\n",
    "        decoded = self.decoder(output.view(output.size(0) * output.size(1), output.size(2)))\n",
    "        result = decoded.view(-1, decoded.size(1))\n",
    "        return result, raw_outputs, outputs\n",
    "\n",
    "    \n",
    "class CustomLinear(lm_rnn.PoolingLinearClassifier):\n",
    "\n",
    "    def forward(self, input):\n",
    "        raw_outputs, outputs = input\n",
    "        output = outputs[-1]\n",
    "        sl,bs,_ = output.size()\n",
    "        avgpool = self.pool(output, bs, False)\n",
    "        mxpool = self.pool(output, bs, True)\n",
    "        x = torch.cat([output[-1], mxpool, avgpool], 1)\n",
    "        for i, l in enumerate(self.layers):\n",
    "            l_x = l(x)\n",
    "            if i != len(self.layers) -1:\n",
    "                x = F.relu(l_x)\n",
    "            else:\n",
    "                x = torch.sigmoid(l_x)\n",
    "        return l_x, raw_outputs, outputs\n",
    "\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 _parameter_dict,\n",
    "                 _device,\n",
    "                 _wgts_e,\n",
    "                 _wgts_d,\n",
    "                 _encargs):\n",
    "        super(LanguageModel, self).__init__()\n",
    "\n",
    "        self.parameter_dict = _parameter_dict\n",
    "        self.device = _device\n",
    "\n",
    "        self.encoder = CustomEncoder(**_encargs).to(self.device)\n",
    "        self.encoder.load_state_dict(_wgts_e)\n",
    "        \"\"\"\n",
    "            Explanation:\n",
    "                400*3 because input is [ h_T, maxpool, meanpool ]\n",
    "                0.4, 0.1 are drops at various layersLM_PATH\n",
    "        \"\"\"\n",
    "        self.linear_dec = CustomDecoder(\n",
    "            _encargs['ntoken'],\n",
    "            n_hid=400,\n",
    "            dropout=0.1 * 0.7,\n",
    "            tie_encoder=self.encoder.encoder,\n",
    "            bias=False\n",
    "        ).to(self.device)\n",
    "\n",
    "        # self.linear_dom = CustomLinear(\n",
    "        #     2,\n",
    "        #     n_hid=400,\n",
    "        #     dropout=0.1 * 0.7,\n",
    "        #     #             tie_encoder=self.encoder.encoder,\n",
    "        #     bias=False\n",
    "        # ).to(self.device)\n",
    "        self.linear_dom = CustomLinear(layers=[400*3, 50, 2], drops=[0.2, 0.1]).to(self.device)\n",
    "        self.encoder.reset()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_enc = self.encoder(x)\n",
    "        return self.linear_dec(x_enc)\n",
    "\n",
    "    def domain(self, x_enc):\n",
    "        x_enc = list(x_enc)\n",
    "        x_enc[1] = [GradReverse.apply(enc_tensr) for enc_tensr in x_enc[1]]\n",
    "        return self.linear_dom(x_enc)[0]\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        # layers = [x for x in self.encoder.layers]\n",
    "        # layers.append(torch.nn.ModuleList([x for x in self.linear_dec.layers]))\n",
    "        # layers.append(torch.nn.ModuleList([x for x in self.linear_dom.layers]))\n",
    "        # return torch.nn.ModuleList(layers)\n",
    "        return self.encoder.layers.extend(self.linear_dec.layers).extend(self.linear_dom.layers)\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            self.eval()\n",
    "            pred = self.forward(x)\n",
    "            self.train()\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "bptt = 70\n",
    "bs = 16\n",
    "opt_fn = partial(torch.optim.Adam, betas=(0.8, 0.99))  # @TODO: find real optimizer, and params\n",
    "\n",
    "# Load the pre-trained model\n",
    "parameter_dict = {'itos2': itos2}\n",
    "dps = list(np.asarray([0.25, 0.1, 0.2, 0.02, 0.15]) * 0.7)\n",
    "encargs = {'ntoken': new_w.shape[0],\n",
    "           'emb_sz': 400, 'n_hid': 1150,\n",
    "           'n_layers': 3, 'pad_token': 0,\n",
    "           'qrnn': False, 'dropouti': dps[0],\n",
    "           'wdrop': dps[2], 'dropoute': dps[3], 'dropouth': dps[4]}\n",
    "\n",
    "# For now, lets assume our best lr = 0.001\n",
    "bestlr = 0.001 * 10\n",
    "lm = LanguageModel(parameter_dict, device, wgts_enc, wgts_dec, encargs)\n",
    "opt = make_opt(lm, opt_fn, lr=bestlr)\n",
    "loss_main_fn = F.cross_entropy\n",
    "loss_aux_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make data iterators and LR iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, lets assume our best lr = 0.001\n",
    "bestlr = 0.001 * 10\n",
    "lm = LanguageModel(parameter_dict, device, wgts_enc, wgts_dec, encargs)\n",
    "opt = make_opt(lm, opt_fn, lr=bestlr)\n",
    "loss_main_fn = F.cross_entropy\n",
    "loss_aux_fn = F.cross_entropy\n",
    "\n",
    "# Make data\n",
    "data_fn_unidomain = partial(text.LanguageModelLoader, bs=bs, bptt=bptt)\n",
    "data_imdb = {'train': np.concatenate(trn_lm), 'valid': np.concatenate(val_lm)}\n",
    "data_wiki = {'train': np.concatenate(wiki_trn_lm), 'valid': np.concatenate(wiki_val_lm)}\n",
    "data_fn = partial(DomainAgnosticSampler, data_fn=data_fn_unidomain)\n",
    "\n",
    "# Set up lr and freeze stuff\n",
    "for grp in opt.param_groups:\n",
    "    grp['lr'] = 0.0\n",
    "opt.param_groups[3]['lr'] = 1e-3 / 2\n",
    "opt.param_groups[4]['lr'] = 1e-3 / 2\n",
    "\n",
    "# lr_args = {'batches':, 'cycles': 1}\n",
    "lr_args = {'iterations': len(data_fn(data_a=data_wiki['train'], data_b=data_imdb['train'])), 'cut_frac': 0.1, 'ratio': 32}\n",
    "lr_schedule = mtlr.LearningRateScheduler(opt, lr_args, mtlr.SlantedTriangularLR)\n",
    "\n",
    "\n",
    "# @TODO: add dom agnostic thing to eval as well?\n",
    "def _eval(y_pred, y_true):\n",
    "    \"\"\"\n",
    "        Expects a batch of input\n",
    "\n",
    "        :param y_pred: tensor of shape (b, nc)\n",
    "        :param y_true: tensor of shape (b, 1)\n",
    "    \"\"\"\n",
    "    return torch.mean((torch.argmax(y_pred, dim=1) == y_true).float())\n",
    "\n",
    "def _eval_dann(y_pred, y_true):\n",
    "    return torch.mean((y_pred.round() == y_true).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'epochs': 1, 'weight_decay': 0, 'data_a': data_imdb, 'data_b': data_wiki,\n",
    "        'device': device, 'opt': opt, 'loss_main_fn': loss_main_fn, 'loss_aux_fn': loss_aux_fn,\n",
    "        'train_fn': lm, 'train_aux_fn': lm.domain, 'predict_fn': lm.predict, 'data_fn': data_fn, 'model': lm,\n",
    "        'eval_fn': _eval, 'eval_aux_fn': _eval_dann, 'batch_start_hook': partial(mtlp.reset_hidden, lm),\n",
    "        'clip_grads_at': -1.0, 'lr_schedule': lr_schedule}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "    \n",
    "        - sample from wiki\n",
    "            - e(x_w)        forward from encoder\n",
    "            - d(e(x_w))     forward from decoder\n",
    "            - backward normally\n",
    "            \n",
    "            - e(x_w)'       grad reverse layer\n",
    "            - d'(e(x_w)')   forward from domain agnostic layer\n",
    "            - backward\n",
    "            \n",
    "        - sample from imdb\n",
    "            - same..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generic_loop(epochs: int,\n",
    "                 device: torch.device,\n",
    "                 opt: torch.optim,\n",
    "                 loss_main_fn: torch.nn,\n",
    "                 loss_aux_fn: torch.nn,\n",
    "                 model: torch.nn.Module,\n",
    "                 train_fn: Callable,\n",
    "                 train_aux_fn: Callable,\n",
    "                 predict_fn: Callable,\n",
    "                 data_a: dict,\n",
    "                 data_b: dict,\n",
    "                 data_fn: classmethod,\n",
    "                 epoch_start_hook: Callable = None,\n",
    "                 epoch_end_hook: Callable = None,\n",
    "                 batch_start_hook: Callable = None,\n",
    "                 batch_end_hook: Callable = None,\n",
    "                 weight_decay: float = 0.0,\n",
    "                 clip_grads_at: float = -1.0,\n",
    "                 lr_schedule=None,\n",
    "                 eval_fn: Callable = None,\n",
    "                 eval_aux_fn: Callable = None) -> (list, list, list):\n",
    "    \"\"\"\n",
    "\n",
    "        A generic training loop, which based on diff hook fns (defined below), should handle anything given to it.\n",
    "\n",
    "        The model need not be an nn.Module,\n",
    "             but should have correctly wired forward and a predict function.\n",
    "\n",
    "        Data should be a dict like so:\n",
    "            {\"train\":{\"x\":np.arr, \"y\":np.arr}, \"val\":{\"x\":np.arr, \"y\":np.arr} }\n",
    "\n",
    "        Train_fn must return both loss and y_pred\n",
    "\n",
    "    :param epochs: number of epochs to train for\n",
    "    :param data: data dict (structure specified above)\n",
    "    :param device: torch device to init the tensors with\n",
    "    :param opt: torch optimizer, with proper param_groups for better lr decay per laye\n",
    "    :param loss_main_fn: torch.nn loss fn for the actual thing\n",
    "    :param loss_aux_fn: torch.nn loss fn for the domain agnostic thing\n",
    "    :param model: torch module (for grad clipping)\n",
    "    :param train_fn: a function which takes x & y, returns loss and y_pred\n",
    "    :param train_aux_fn: a function which takes x & y, returns loss and y_pred_aux\n",
    "    :param predict_fn: a fn which takes x and returns y_pred\n",
    "    :param epoch_start_hook: a fn that can be called @ start of every epoch (returns model, opt)\n",
    "    :param epoch_end_hook: a fn that can be called @ end of every epoch (returns model, opt)\n",
    "    :param batch_start_hook: a fn that can be called @ start of every batch (returns model, opt)\n",
    "    :param batch_end_hook: a fn that can be called @r end of every batch (returns model, opt)\n",
    "    :param weight_decay: a L2 ratio (as mentioned in (https://arxiv.org/pdf/1711.05101.pdf)\n",
    "    :param clip_grads_at: in case you want gradients clipped, send the max val here\n",
    "    :param lr_schedule: a schedule that is called @ every batch start.\n",
    "    :param data_fn: a class to which we can pass X and Y, and get an iterator.\n",
    "    :param eval_fn: function which when given pred and true, returns acc\n",
    "    :param eval_aux_fn: same as eval_fn but for domain classifier's output.\n",
    "    :return: traces\n",
    "    \"\"\"\n",
    "\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    train_acc_aux = []\n",
    "    val_acc = []\n",
    "    lrs = []\n",
    "\n",
    "    # Epoch level\n",
    "    for e in range(epochs):\n",
    "\n",
    "        per_epoch_loss = []\n",
    "        per_epoch_tr_acc = []\n",
    "        per_epoch_tr_acc_aux = []\n",
    "\n",
    "        # Train\n",
    "        with Timer() as timer:\n",
    "\n",
    "            # @TODO: Add hook at start of epoch (how to decide what goes in)\n",
    "            if epoch_start_hook: epoch_start_hook()\n",
    "\n",
    "            # Make data\n",
    "            trn_dl = data_fn(data_a=data_a['train'], data_b=data_b['train'])\n",
    "            val_dl = data_fn(data_a=data_a['valid'], data_b=data_b['valid'])\n",
    "\n",
    "            for x, y, y_aux in tqdm(trn_dl):\n",
    "\n",
    "                if batch_start_hook: batch_start_hook()\n",
    "                opt.zero_grad()\n",
    "\n",
    "                if lr_schedule: lrs.append(update_lr(opt, lr_schedule.get()))\n",
    "\n",
    "                # 0. Convert np arrs to torch tensors\n",
    "                _x = torch.tensor(x, dtype=torch.long, device=device)\n",
    "                _y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "                _y_aux = torch.tensor(y_aux, dtype=torch.long, device=device)\n",
    "\n",
    "                # A: Normal stuff\n",
    "                op = train_fn(_x)\n",
    "                y_pred = op[0]\n",
    "                loss = loss_main_fn(y_pred, _y)\n",
    "\n",
    "                # Pass regular gradients\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                # B: Domain agnostic stuff\n",
    "                y_pred_aux = train_aux_fn(op[1:])\n",
    "                loss_aux = loss_aux_fn(y_pred_aux, _y_aux)\n",
    "\n",
    "                # Logging\n",
    "                per_epoch_tr_acc.append(eval_fn(y_pred=y_pred, y_true=_y).item())\n",
    "                per_epoch_tr_acc_aux.append(eval_fn(y_pred=y_pred_aux, y_true=_y_aux).item())\n",
    "                per_epoch_loss.append(loss.item())\n",
    "\n",
    "                # Pass aux gradients\n",
    "                loss_aux.backward(retain_graph=False)\n",
    "\n",
    "                # Optimizer Step\n",
    "                if clip_grads_at > 0.0: torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grads_at)\n",
    "                for group in opt.param_groups:\n",
    "                    for param in group['params']:\n",
    "                        param.data = param.data.add(-weight_decay * group['lr'], param.data)\n",
    "\n",
    "                opt.step()\n",
    "                if batch_end_hook: batch_end_hook()\n",
    "\n",
    "            if epoch_end_hook: epoch_end_hook()\n",
    "\n",
    "        # Val\n",
    "        with torch.no_grad():\n",
    "\n",
    "            per_epoch_vl_acc = []\n",
    "            for x, y, y_aux in tqdm(val_dl):\n",
    "                _x = torch.tensor(x, dtype=torch.long, device=device)\n",
    "                _y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "\n",
    "                y_pred = predict_fn(_x)[0]\n",
    "\n",
    "                per_epoch_vl_acc.append(eval_fn(y_pred, _y).item())\n",
    "\n",
    "        # Bookkeep\n",
    "        train_acc.append(np.mean(per_epoch_tr_acc))\n",
    "        train_acc_aux.append(np.mean(per_epoch_tr_acc_aux))\n",
    "        train_loss.append(np.mean(per_epoch_loss))\n",
    "        val_acc.append(np.mean(per_epoch_vl_acc))\n",
    "\n",
    "        print(\"Epoch: %(epo)03d | Loss: %(loss).5f | Tr_c: %(tracc)0.5f | Tr_aux: %(tracc_aux)0.5f | \"\n",
    "              \"Vl_c: %(vlacc)0.5f | Time: %(time).3f min\"\n",
    "              % {'epo': e,\n",
    "                 'loss': float(np.mean(per_epoch_loss)),\n",
    "                 'tracc': float(np.mean(per_epoch_tr_acc)),\n",
    "                 'tracc_aux': float(np.mean(per_epoch_tr_acc_aux)),\n",
    "                 'vlacc': float(np.mean(per_epoch_vl_acc)),\n",
    "                 'time': timer.interval / 60.0})\n",
    "\n",
    "    return train_acc, train_acc_aux, train_loss, val_acc, lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.89it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 42.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000 | Loss: 4.89826 | Tr_c: 0.21558 | Tr_aux: 0.45590 | Vl_c: 0.22641 | Time: 0.484 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.237128297390677e-05,\n",
       " 8.416533573215762e-05,\n",
       " 0.00021882987290360977,\n",
       " 0.0005689576695493855,\n",
       " 0.0014792899408284023,\n",
       " 0.003846153846153846,\n",
       " 0.01]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/287 [00:00<00:40,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.237128297390677e-05, 8.416533573215762e-05, 0.00021882987290360977, 0.0005689576695493855, 0.0014792899408284023, 0.003846153846153846, 0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:28<00:00,  9.77it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 44.33it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000 | Loss: 4.59243 | Tr_c: 0.23550 | Tr_aux: 0.94774 | Vl_c: 0.25879 | Time: 0.483 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.89it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 43.10it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Loss: 4.29103 | Tr_c: 0.25569 | Tr_aux: 0.90396 | Vl_c: 0.26637 | Time: 0.484 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.79it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 41.69it/s]\n",
      "  0%|          | 1/287 [00:00<00:41,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002 | Loss: 4.25157 | Tr_c: 0.25860 | Tr_aux: 0.78571 | Vl_c: 0.27267 | Time: 0.489 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.43it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 41.90it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003 | Loss: 4.21146 | Tr_c: 0.26246 | Tr_aux: 0.75490 | Vl_c: 0.27403 | Time: 0.490 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.38it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 40.77it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004 | Loss: 4.18219 | Tr_c: 0.26550 | Tr_aux: 0.73421 | Vl_c: 0.27446 | Time: 0.491 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:30<00:00,  9.53it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 42.61it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005 | Loss: 4.15557 | Tr_c: 0.26643 | Tr_aux: 0.71625 | Vl_c: 0.27546 | Time: 0.502 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.61it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 41.42it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006 | Loss: 4.13121 | Tr_c: 0.26877 | Tr_aux: 0.70884 | Vl_c: 0.27979 | Time: 0.494 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.33it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 41.21it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007 | Loss: 4.11381 | Tr_c: 0.27055 | Tr_aux: 0.69980 | Vl_c: 0.27672 | Time: 0.496 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.24it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 40.54it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008 | Loss: 4.09879 | Tr_c: 0.27211 | Tr_aux: 0.70819 | Vl_c: 0.28219 | Time: 0.499 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.86it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 40.62it/s]\n",
      "  0%|          | 1/287 [00:00<00:42,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009 | Loss: 4.08807 | Tr_c: 0.27274 | Tr_aux: 0.70536 | Vl_c: 0.28274 | Time: 0.492 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.63it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 42.74it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010 | Loss: 4.08046 | Tr_c: 0.27342 | Tr_aux: 0.69752 | Vl_c: 0.28086 | Time: 0.492 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.34it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 41.88it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011 | Loss: 4.07065 | Tr_c: 0.27422 | Tr_aux: 0.70449 | Vl_c: 0.28099 | Time: 0.494 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.69it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 42.32it/s]\n",
      "  0%|          | 1/287 [00:00<00:40,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012 | Loss: 4.07142 | Tr_c: 0.27467 | Tr_aux: 0.70057 | Vl_c: 0.28110 | Time: 0.494 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.36it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 42.32it/s]\n",
      "  0%|          | 1/287 [00:00<00:41,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013 | Loss: 4.06179 | Tr_c: 0.27535 | Tr_aux: 0.69839 | Vl_c: 0.28214 | Time: 0.485 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:29<00:00,  9.46it/s]\n",
      "100%|██████████| 29/29 [00:00<00:00, 41.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014 | Loss: 4.06229 | Tr_c: 0.27568 | Tr_aux: 0.70743 | Vl_c: 0.28214 | Time: 0.496 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "traces_start = generic_loop(**args)\n",
    "\n",
    "# Now unfreeze all layers and apply discr\n",
    "for grp in opt.param_groups:\n",
    "    grp['lr'] = bestlr\n",
    "\n",
    "lr_dscr = lambda opt, lr, fctr=2.6: [lr / (fctr ** i) for i in range(len(opt.param_groups))[::-1]]\n",
    "update_lr(opt, lr_dscr(opt, bestlr))\n",
    "\n",
    "if DEBUG:\n",
    "    print([x['lr'] for x in opt.param_groups])\n",
    "\n",
    "lr_args = {'iterations': len(data_fn(data_a=data_wiki['train'], data_b=data_imdb['train']))*15, 'cut_frac': 0.1, 'ratio': 32}\n",
    "lr_schedule = mtlr.LearningRateScheduler(opt, lr_args, mtlr.SlantedTriangularLR)\n",
    "args['lr_schedule'] = lr_schedule\n",
    "args['epochs'] = 15\n",
    "\n",
    "traces_main = generic_loop(**args)\n",
    "traces = [a+b for a, b in zip(traces_start, traces_main)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (16, 8)\n",
    "\n",
    "def plot_accs(tra, vla, axa):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "#     ax = fig.add_axes((0.1, 0.2, 0.8, 0.7))\n",
    "#     ax.spines['right'].set_color('none')\n",
    "#     ax.spines['top'].set_color('none')\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "    plt.plot(tra, label=f\"Train Acc\", linewidth=3)\n",
    "    plt.plot(vla, label=f\"Valid Acc\", linewidth=3)\n",
    "    plt.plot(axa, label=f\"DAdNN Acc\", linewidth=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accs(traces[0], traces[1], traces[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMPPATH = PATH / 'trim_default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the traces\n",
    "with open(DUMPPATH/'unsup_dann_traces.pkl', 'wb+') as fl:\n",
    "    pickle.dump(traces, fl)\n",
    "\n",
    "# The vocab and the models\n",
    "pickle.dump(itos, open(DUMPPATH / 'itos_dann.pkl', 'wb'))\n",
    "torch.save(lm.state_dict(), DUMPPATH / 'unsup_dann_model.torch')\n",
    "torch.save(lm.encoder.state_dict(), DUMPPATH / 'unsup_dann_model_enc.torch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
