{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0fe66fd110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# External Lib imports\n",
    "import collections\n",
    "import html\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'\n",
    "\n",
    "# FastAI Imports\n",
    "from fastai import text, core, lm_rnn\n",
    "\n",
    "# Torch imports\n",
    "import torch.nn as nn\n",
    "import torch.tensor as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Mytorch imports\n",
    "from mytorch import loops as mtlp\n",
    "from mytorch.utils.goodies import *\n",
    "from mytorch import lriters as mtlr\n",
    "\n",
    "device = torch.device('cuda')\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainAgnosticSampler:\n",
    "    \"\"\" Sample data for language model training from two different domains in one batch. \"\"\"\n",
    "    \n",
    "    def __init__(self, data_fn, data_a, data_b):\n",
    "        \"\"\"\n",
    "            Here, data_fn would be something like \n",
    "                `partial(text.LanguageModelLoader, bs=bs, bptt=bptt)`\n",
    "            And data_a/b would be something like \n",
    "                `{'train': np.concatenate(trn_lm), 'valid': np.concatenate(val_lm)}['train']`\n",
    "            data_fn (fastai's language model loader) flattens y and returns x of seqlen, batchsize\n",
    "        \"\"\"\n",
    "        self.args = {'data_fn': data_fn, 'data_a':data_a, 'data_b':data_b}        \n",
    "        self.reset(**self.args)\n",
    "        \n",
    "    def reset(self, data_fn, data_a, data_b):\n",
    "        self.itera = iter(data_fn(data_a))\n",
    "        self.iterb = iter(data_fn(data_b))\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "        \n",
    "    def __next__(self):\n",
    "        x_a, y_a = self.itera.__next__()\n",
    "        x_b, y_b = self.iterb.__next__()\n",
    "        return self._combine_batch_(x_a, x_b, y_a, y_b)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return min(len(self.args['data_fn'](self.args['data_a'])), \n",
    "                   len(self.args['data_fn'](self.args['data_b'])))\n",
    "        \n",
    "    @staticmethod\n",
    "    def _combine_batch_(x_a, x_b, y_a, y_b):\n",
    "        \"\"\"\n",
    "            :param x_a is a np.arr looks like seqlen, batchsize\n",
    "            :param y_a is a corresponding np.arr (one word ahead than x_a) which is a flattened x_a.shape mat\n",
    "             Same for x_b, y_b\n",
    "             \n",
    "             Returns x, y, y_dom in similar shapes as input\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get them to interpretable shapes\n",
    "        y_a = y_a.reshape(x_a.shape).transpose(1, 0)\n",
    "        y_b = y_b.reshape(x_b.shape).transpose(1, 0)\n",
    "        x_a = x_a.transpose(1, 0)\n",
    "        x_b = x_b.transpose(1, 0)\n",
    "        \n",
    "        b_bs, b_sl = x_a.shape[0], min(x_a.shape[1], x_b.shape[1])\n",
    "        \n",
    "        # Concatenate to make an x and y\n",
    "        x = np.concatenate((x_a[:,:b_sl], x_b[:, :b_sl]))\n",
    "        y = np.concatenate((y_a[:,:b_sl], y_b[:, :b_sl]))\n",
    "        \n",
    "        # Shuffle and remember shuffle index to make y labels for domain agnostic training\n",
    "        intrp = np.arange(b_bs*2)\n",
    "        np.random.shuffle(intrp)\n",
    "        y_dom = (intrp >=  b_bs)*1\n",
    "        x = x[intrp]\n",
    "        y = y[intrp]\n",
    "        \n",
    "        x = x.transpose(1, 0)\n",
    "        y = y.transpose(1, 0).reshape(np.prod(y.shape))\n",
    "        \n",
    "        return x, y, y_dom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "\n",
    "# Path fields\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "WIKI_DATA_PATH = Path('raw/wikitext/wikitext-103/')\n",
    "WIKI_DATA_PATH.mkdir(exist_ok=True)\n",
    "IMDB_DATA_PATH = Path('raw/imdb/aclImdb/')\n",
    "IMDB_DATA_PATH.mkdir(exist_ok=True)\n",
    "PATH = Path('resources/proc/imdb')\n",
    "DATA_PROC_PATH = PATH / 'data'\n",
    "DATA_LM_PATH = PATH / 'datalm'\n",
    "\n",
    "LM_PATH = Path('resources/models')\n",
    "LM_PATH.mkdir(exist_ok=True)\n",
    "PRE_PATH = LM_PATH / 'wt103'\n",
    "PRE_LM_PATH = PRE_PATH / 'fwd_wt103.h5'\n",
    "CLASSES = ['neg', 'pos', 'unsup']\n",
    "WIKI_CLASSES = ['wiki.train.tokens', 'wiki.valid.tokens', 'wiki.test.tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000 25000\n"
     ]
    }
   ],
   "source": [
    "def get_texts_org(path):\n",
    "    texts, labels = [], []\n",
    "    for idx, label in enumerate(CLASSES):\n",
    "        for fname in (path / label).glob('*.*'):\n",
    "            texts.append(fname.open('r', encoding='utf-8').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts), np.array(labels)\n",
    "\n",
    "trn_texts, trn_labels = get_texts_org(IMDB_DATA_PATH / 'train')\n",
    "val_texts, val_labels = get_texts_org(IMDB_DATA_PATH / 'test')\n",
    "col_names = ['labels', 'text']\n",
    "print(len(trn_texts), len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859955 1841\n"
     ]
    }
   ],
   "source": [
    "def is_valid_sent(x):\n",
    "    x = x.strip()\n",
    "    if len(x) == 0: return False\n",
    "    if x[0] == '=' and x[-1] == '=': return False\n",
    "    return True\n",
    "def wiki_get_texts_org(path):\n",
    "    texts = []\n",
    "    for idx, label in enumerate(WIKI_CLASSES):\n",
    "        with open(path / label, encoding='utf-8') as f:\n",
    "            texts.append([sent.strip() for sent in f.readlines() if is_valid_sent(sent)])\n",
    "    return tuple(texts)\n",
    "wiki_trn_texts, wiki_val_texts, wiki_tst_texts = wiki_get_texts_org(WIKI_DATA_PATH)\n",
    "print(len(wiki_trn_texts), len(wiki_val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts, val_texts = trn_texts[:1000], val_texts[:1000]\n",
    "wiki_trn_texts, wiki_val_texts, wiki_tst_texts = wiki_trn_texts[:1000], wiki_val_texts[:1000], wiki_tst_texts[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "trn_idx = np.random.permutation(len(trn_texts))\n",
    "val_idx = np.random.permutation(len(val_texts))\n",
    "\n",
    "trn_texts, trn_labels = trn_texts[trn_idx], trn_labels[trn_idx]\n",
    "val_texts, val_labels = val_texts[val_idx], val_labels[val_idx]\n",
    "\n",
    "# Shuffle data (wiki)\n",
    "np.random.shuffle(wiki_trn_texts)\n",
    "np.random.shuffle(wiki_val_texts)\n",
    "np.random.shuffle(wiki_tst_texts)\n",
    "\n",
    "wiki_trn_labels = [0 for _ in wiki_trn_texts]\n",
    "wiki_val_labels = [0 for _ in wiki_val_texts]\n",
    "wiki_tst_labels = [0 for _ in wiki_val_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe black magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     2,
     8,
     16,
     22
    ]
   },
   "outputs": [],
   "source": [
    "chunksize = 24000\n",
    "re1 = re.compile(r'  +')\n",
    "def _fixup_(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n",
    "        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "def _get_texts_(df, n_lbls=1):\n",
    "    labels = df.iloc[:, range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls + 1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = list(texts.apply(_fixup_).values)\n",
    "\n",
    "    tok = text.Tokenizer().proc_all_mp(core.partition_by_cores(texts))\n",
    "    return tok, list(labels)\n",
    "def _simple_apply_fixup_(df):\n",
    "    labels = [0] * df.shape[0]\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df.text\n",
    "    texts = list(texts.apply(_fixup_).values)\n",
    "    tok = text.Tokenizer().proc_all_mp(core.partition_by_cores(texts))\n",
    "    return tok, list(labels)   \n",
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = _get_texts_(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 200\n",
      "Trn: (1800, 1800), Val: (200, 200) \n"
     ]
    }
   ],
   "source": [
    "trn_texts, val_texts = sklearn.model_selection.train_test_split(\n",
    "        np.concatenate([trn_texts, val_texts]), test_size=0.1)\n",
    "\n",
    "if DEBUG:\n",
    "    print(len(trn_texts), len(val_texts))\n",
    "\n",
    "df_trn = pd.DataFrame({'text': trn_texts, 'labels': [0] * len(trn_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text': val_texts, 'labels': [0] * len(val_texts)}, columns=col_names)\n",
    "\n",
    "trn_tok, trn_labels = _simple_apply_fixup_(df_trn)\n",
    "val_tok, val_labels = _simple_apply_fixup_(df_val)\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"Trn: {len(trn_tok), len(trn_labels)}, Val: {len(val_tok), len(val_labels)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 300\n",
      "Trn: (2700, 2700), Val: (300, 300) \n"
     ]
    }
   ],
   "source": [
    "wiki_trn_texts, wiki_val_texts = sklearn.model_selection.train_test_split(\n",
    "        np.concatenate([wiki_trn_texts, wiki_val_texts, wiki_tst_texts]), test_size=0.1)\n",
    "\n",
    "if DEBUG:\n",
    "    print(len(wiki_trn_texts), len(wiki_val_texts))\n",
    "    \n",
    "wiki_df_trn = pd.DataFrame({'text':wiki_trn_texts, 'labels': [0] * len(wiki_trn_texts)}, columns=col_names)\n",
    "wiki_df_val = pd.DataFrame({'text':wiki_val_texts, 'labels': [0] * len(wiki_val_texts)}, columns=col_names)\n",
    "\n",
    "wiki_trn_tok, wiki_trn_labels = _simple_apply_fixup_(wiki_df_trn)\n",
    "wiki_val_tok, wiki_val_labels = _simple_apply_fixup_(wiki_df_val)\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"Trn: {len(wiki_trn_tok), len(wiki_trn_labels)}, Val: {len(wiki_val_tok), len(wiki_val_labels)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Now we make vocabulary, select 60k most freq words \\n        (we do this looking only at imdb, and ignore wiki here)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Now we make vocabulary, select 60k most freq words \n",
    "        (we do this looking only at imdb, and ignore wiki here)\n",
    "'''\n",
    "\n",
    "freq = Counter(p for o in trn_tok for p in o)\n",
    "# freq.most_common(25)\n",
    "max_vocab = 60000\n",
    "min_freq = 2\n",
    "\n",
    "itos = [o for o, c in freq.most_common(max_vocab) if c > min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "stoi = collections.defaultdict(lambda: 0, {v: k for k, v in enumerate(itos)})\n",
    "vs = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITOS: 9314, STOI: 25161\n",
      "ITOS: 9314, STOI: 36993\n"
     ]
    }
   ],
   "source": [
    "trn_lm = np.array([[stoi[o] for o in p] for p in trn_tok])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in val_tok])\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"ITOS: {len(itos)}, STOI: {len(stoi)}\")\n",
    "    \n",
    "wiki_trn_lm = np.array([[stoi[o] for o in p] for p in wiki_trn_tok])\n",
    "wiki_val_lm = np.array([[stoi[o] for o in p] for p in wiki_val_tok])\n",
    "    \n",
    "if DEBUG:\n",
    "    print(f\"ITOS: {len(itos)}, STOI: {len(stoi)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Now we pull pretrained models from disk\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Now we pull pretrained models from disk\n",
    "\"\"\"\n",
    "em_sz, nh, nl = 400, 1150, 3\n",
    "# PRE_PATH = PATH / 'models' / 'wt103'\n",
    "# PRE_LM_PATH = PRE_PATH / 'fwd_wt103.h5'\n",
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)\n",
    "enc_wgts = core.to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)\n",
    "itos2 = pickle.load((PRE_PATH / 'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda: -1, {v: k for k, v in enumerate(itos2)})\n",
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for i, w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r >= 0 else row_m\n",
    "\n",
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))\n",
    "wgts_enc = {'.'.join(k.split('.')[1:]): val\n",
    "            for k, val in wgts.items() if k[0] == '0'}\n",
    "wgts_dec = {'.'.join(k.split('.')[1:]): val\n",
    "            for k, val in wgts.items() if k[0] == '1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0,
     14,
     23
    ]
   },
   "outputs": [],
   "source": [
    "class CustomDecoder(text.LinearDecoder):\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return torch.nn.ModuleList([self.decoder, self.dropout])\n",
    "\n",
    "    def forward(self, input):\n",
    "        raw_outputs, outputs = input\n",
    "        output = self.dropout(outputs[-1])\n",
    "        decoded = self.decoder(output.view(output.size(0) * output.size(1), output.size(2)))\n",
    "        result = decoded.view(-1, decoded.size(1))\n",
    "        return result, raw_outputs, outputs\n",
    "\n",
    "\n",
    "class CustomEncoder(lm_rnn.RNN_Encoder):\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return torch.nn.ModuleList([torch.nn.ModuleList([self.rnns[0], self.dropouths[0]]),\n",
    "                                    torch.nn.ModuleList([self.rnns[1], self.dropouths[1]]),\n",
    "                                    torch.nn.ModuleList([self.rnns[2], self.dropouths[2]])])\n",
    "\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 _parameter_dict,\n",
    "                 _device,\n",
    "                 _wgts_e,\n",
    "                 _wgts_d,\n",
    "                 _encargs):\n",
    "        super(LanguageModel, self).__init__()\n",
    "\n",
    "        self.parameter_dict = _parameter_dict\n",
    "        self.device = _device\n",
    "\n",
    "        self.encoder = CustomEncoder(**_encargs).to(self.device)\n",
    "        self.encoder.load_state_dict(_wgts_e)\n",
    "        \"\"\"\n",
    "            Explanation:\n",
    "                400*3 because input is [ h_T, maxpool, meanpool ]\n",
    "                0.4, 0.1 are drops at various layersLM_PATH\n",
    "        \"\"\"\n",
    "        self.linear_dec = CustomDecoder(\n",
    "            _encargs['ntoken'],\n",
    "            n_hid=400,\n",
    "            dropout=0.1 * 0.7,\n",
    "            tie_encoder=self.encoder.encoder,\n",
    "            bias=False\n",
    "        ).to(self.device)\n",
    "\n",
    "#         self.linear_dom = CustomLinear(\n",
    "#             2,\n",
    "#             n_hid=400,\n",
    "#             dropout=0.1 * 0.7,\n",
    "#             #             tie_encoder=self.encoder.encoder,\n",
    "#             bias=False\n",
    "#         ).to(self.device)\n",
    "        self.linear_dom = lm_rnn.PoolingLinearClassifier(layers=[400*3, 50, 2], drops=[0.2, 0.1]).to(self.device)\n",
    "        self.encoder.reset()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_enc = self.encoder(x)\n",
    "        return self.linear_dec(x_enc)\n",
    "\n",
    "    def domain(self, x_enc):\n",
    "        x_enc = list(x_enc)\n",
    "        x_enc[1] = [GradReverse.apply(enc_tensr) for enc_tensr in x_enc[1]]\n",
    "        return self.linear_dom(x_enc)[0]\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "#         layers = [x for x in self.encoder.layers]\n",
    "#         layers.append(torch.nn.ModuleList([x for x in self.linear_dec.layers]))\n",
    "#         layers.append(torch.nn.ModuleList([x for x in self.linear_dom.layers]))\n",
    "#         return torch.nn.ModuleList(layers)\n",
    "        return self.encoder.layers.extend(self.linear_dec.layers).extend(self.linear_dom.layers)\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            self.eval()\n",
    "            pred = self.forward(x)\n",
    "            self.train()\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "bptt = 70\n",
    "bs = 24\n",
    "opt_fn = partial(torch.optim.Adam, betas=(0.8, 0.99))  # @TODO: find real optimizer, and params\n",
    "\n",
    "# Load the pre-trained model\n",
    "parameter_dict = {'itos2': itos2}\n",
    "dps = list(np.asarray([0.25, 0.1, 0.2, 0.02, 0.15]) * 0.7)\n",
    "encargs = {'ntoken': new_w.shape[0],\n",
    "           'emb_sz': 400, 'n_hid': 1150,\n",
    "           'n_layers': 3, 'pad_token': 0,\n",
    "           'qrnn': False, 'dropouti': dps[0],\n",
    "           'wdrop': dps[2], 'dropoute': dps[3], 'dropouth': dps[4]}\n",
    "\n",
    "# For now, lets assume our best lr = 0.001\n",
    "bestlr = 0.001 * 10\n",
    "lm = LanguageModel(parameter_dict, device, wgts_enc, wgts_dec, encargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = make_opt(lm, opt_fn, lr=bestlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_main_fn = F.cross_entropy\n",
    "loss_aux_fn = F.cross_entropy\n",
    "\n",
    "# Make data\n",
    "data_fn_unidomain = partial(text.LanguageModelLoader, bs=bs, bptt=bptt)\n",
    "data_imdb = {'train': np.concatenate(trn_lm), 'valid': np.concatenate(val_lm)}\n",
    "data_wiki = {'train': np.concatenate(wiki_trn_lm), 'valid': np.concatenate(wiki_val_lm)}\n",
    "data_fn = partial(DomainAgnosticSampler, data_fn=data_fn_unidomain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up lr and freeze stuff\n",
    "for grp in opt.param_groups:\n",
    "    grp['lr'] = 0.0\n",
    "opt.param_groups[3]['lr'] = 1e-3 / 2\n",
    "opt.param_groups[4]['lr'] = 1e-3 / 2\n",
    "\n",
    "# lr_args = {'batches':, 'cycles': 1}\n",
    "lr_args = {'iterations': len(data_fn(data_a=data_wiki['train'], data_b=data_imdb['train'])), 'cut_frac': 0.1, 'ratio': 32}\n",
    "lr_schedule = mtlr.LearningRateScheduler(opt, lr_args, mtlr.SlantedTriangularLR)\n",
    "\n",
    "# @TODO: add dom agnostic thing to eval as well?\n",
    "def _eval(y_pred, y_true):\n",
    "    \"\"\"\n",
    "        Expects a batch of input\n",
    "\n",
    "        :param y_pred: tensor of shape (b, nc)\n",
    "        :param y_true: tensor of shape (b, 1)\n",
    "    \"\"\"\n",
    "    return torch.mean((torch.argmax(y_pred, dim=1) == y_true).float())\n",
    "\n",
    "\n",
    "args = {'epochs': 1, 'weight_decay': 0, 'data_a': data_imdb, 'data_b': data_wiki,\n",
    "        'device': device, 'opt': opt, 'loss_main_fn': loss_main_fn, 'loss_aux_fn': loss_aux_fn,\n",
    "        'train_fn': lm, 'train_aux_fn': lm.domain, 'predict_fn': lm.predict, 'data_fn': data_fn, 'model': lm,\n",
    "        'eval_fn': _eval, 'batch_start_hook': partial(mtlp.reset_hidden, lm),\n",
    "        'clip_grads_at': -1.0, 'lr_schedule': lr_schedule}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "diter = data_fn(data_a=data_imdb['train'], data_b=data_wiki['train'])\n",
    "for x,y, y_dom in diter:\n",
    "    print(x.shape, y.shape, y_dom.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generic_loop(epochs: int,\n",
    "                 device: torch.device,\n",
    "                 opt: torch.optim,\n",
    "                 loss_main_fn: torch.nn,\n",
    "                 loss_aux_fn: torch.nn,\n",
    "                 model: torch.nn.Module,\n",
    "                 train_fn: Callable,\n",
    "                 train_aux_fn: Callable,\n",
    "                 predict_fn: Callable,\n",
    "                 data_a: dict,\n",
    "                 data_b: dict,\n",
    "                 data_fn: classmethod,\n",
    "                 epoch_start_hook: Callable = None,\n",
    "                 epoch_end_hook: Callable = None,\n",
    "                 batch_start_hook: Callable = None,\n",
    "                 batch_end_hook: Callable = None,\n",
    "                 weight_decay: float = 0.0,\n",
    "                 clip_grads_at: float = -1.0,\n",
    "                 lr_schedule=None,\n",
    "                 eval_fn: Callable = None) -> (list, list, list):\n",
    "    \"\"\"\n",
    "\n",
    "        A generic training loop, which based on diff hook fns (defined below), should handle anything given to it.\n",
    "\n",
    "        The model need not be an nn.Module,\n",
    "             but should have correctly wired forward and a predict function.\n",
    "\n",
    "        Data should be a dict like so:\n",
    "            {\"train\":{\"x\":np.arr, \"y\":np.arr}, \"val\":{\"x\":np.arr, \"y\":np.arr} }\n",
    "\n",
    "        Train_fn must return both loss and y_pred\n",
    "\n",
    "    :param epochs: number of epochs to train for\n",
    "    :param data: data dict (structure specified above)\n",
    "    :param device: torch device to init the tensors with\n",
    "    :param opt: torch optimizer, with proper param_groups for better lr decay per laye\n",
    "    :param loss_main_fn: torch.nn loss fn for the actual thing\n",
    "    :param loss_aux_fn: torch.nn loss fn for the domain agnostic thing\n",
    "    :param model: torch module (for grad clipping)\n",
    "    :param train_fn: a function which takes x & y, returns loss and y_pred\n",
    "    :param train_aux_fn: a function which takes x & y, returns loss and y_pred_aux\n",
    "    :param predict_fn: a fn which takes x and returns y_pred\n",
    "    :param epoch_start_hook: a fn that can be called @ start of every epoch (returns model, opt)\n",
    "    :param epoch_end_hook: a fn that can be called @ end of every epoch (returns model, opt)\n",
    "    :param batch_start_hook: a fn that can be called @ start of every batch (returns model, opt)\n",
    "    :param batch_end_hook: a fn that can be called @r end of every batch (returns model, opt)\n",
    "    :param weight_decay: a L2 ratio (as mentioned in (https://arxiv.org/pdf/1711.05101.pdf)\n",
    "    :param clip_grads_at: in case you want gradients clipped, send the max val here\n",
    "    :param lr_schedule: a schedule that is called @ every batch start.\n",
    "    :param data_fn: a class to which we can pass X and Y, and get an iterator.\n",
    "    :param eval_fn: (optional) train_dom_fnfunction which when given pred and true, returns acc\n",
    "    :return: traces\n",
    "    \"\"\"\n",
    "\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    lrs = []\n",
    "\n",
    "    # Epoch level\n",
    "    for e in range(epochs):\n",
    "\n",
    "        per_epoch_loss = []\n",
    "        per_epoch_tr_acc = []\n",
    "\n",
    "        # Train\n",
    "        with Timer() as timer:\n",
    "\n",
    "            # @TODO: Add hook at start of epoch (how to decide what goes in)\n",
    "            if epoch_start_hook: epoch_start_hook()\n",
    "\n",
    "            # Make data\n",
    "            trn_dl = data_fn(data_a=data_a['train'], data_b=data_b['train'])\n",
    "            val_dl = data_fn(data_a=data_a['valid'], data_b=data_b['valid'])\n",
    "\n",
    "            for x, y, y_aux in tqdm(trn_dl):\n",
    "\n",
    "                if batch_start_hook: batch_start_hook()\n",
    "                opt.zero_grad()\n",
    "\n",
    "                if lr_schedule: lrs.append(update_lr(opt, lr_schedule.get()))\n",
    "\n",
    "                # 0: Convert numpy tensors to torch tensors\n",
    "                _x = torch.tensor(x, dtype=torch.long, device=device)\n",
    "                _y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "                _y_aux = torch.tensor(y_aux, dtype=torch.long, device=device)\n",
    "                \n",
    "                # A: Normal Stuff\n",
    "                op = train_fn(_x)\n",
    "                y_pred = op[0]\n",
    "                loss = loss_main_fn(y_pred, _y)\n",
    "\n",
    "                # Logging\n",
    "                per_epoch_tr_acc.append(eval_fn(y_pred=y_pred, y_true=_y).item())\n",
    "                per_epoch_loss.append(loss.item())\n",
    "\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                # B: Domain agnostic stuff\n",
    "                y_pred_aux = train_aux_fn(op[1:])                \n",
    "#                 return y_pred_aux, _y_aux\n",
    "                loss_aux = loss_aux_fn(y_pred_aux, _y_aux)\n",
    "\n",
    "                # @TODO: logging here bitte\n",
    "                loss_aux.backward()\n",
    "\n",
    "                # Optimizer Step\n",
    "                if clip_grads_at > 0.0: torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grads_at)\n",
    "                for group in opt.param_groups:\n",
    "                    for param in group['params']:\n",
    "                        param.data = param.data.add(-weight_decay * group['lr'], param.data)\n",
    "\n",
    "                opt.step()\n",
    "                if batch_end_hook: batch_end_hook()\n",
    "\n",
    "            if epoch_end_hook: epoch_end_hook()\n",
    "\n",
    "        # Val\n",
    "        with torch.no_grad():\n",
    "\n",
    "            per_epoch_vl_acc = []\n",
    "            for x, y, y_aux in tqdm(val_dl):\n",
    "                _x = torch.tensor(x, dtype=torch.long, device=device)\n",
    "                _y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "\n",
    "                y_pred = predict_fn(_x)[0]\n",
    "\n",
    "                per_epoch_vl_acc.append(eval_fn(y_pred, _y).item())\n",
    "\n",
    "        # Bookkeep\n",
    "        train_acc.append(np.mean(per_epoch_tr_acc))\n",
    "        train_loss.append(np.mean(per_epoch_loss))\n",
    "        val_acc.append(np.mean(per_epoch_vl_acc))\n",
    "\n",
    "        print(\"Epoch: %(epo)03d | Loss: %(loss).5f | Tr_c: %(tracc)0.5f | Vl_c: %(vlacc)0.5f | Time: %(time).3f min\"\n",
    "              % {'epo': e,\n",
    "                 'loss': float(np.mean(per_epoch_loss)),\n",
    "                 'tracc': float(np.mean(per_epoch_tr_acc)),\n",
    "                 'vlacc': float(np.mean(per_epoch_vl_acc)),\n",
    "                 'time': timer.interval / 60.0})\n",
    "\n",
    "    return train_acc, train_loss, val_acc, lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.91it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 32.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000 | Loss: 4.93077 | Tr_c: 0.21300 | Vl_c: 0.22420 | Time: 0.403 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "traces_start = generic_loop(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.237128297390677e-05,\n",
       " 8.416533573215762e-05,\n",
       " 0.00021882987290360977,\n",
       " 0.0005689576695493855,\n",
       " 0.0014792899408284023,\n",
       " 0.003846153846153846,\n",
       " 0.01]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.237128297390677e-05, 8.416533573215762e-05, 0.00021882987290360977, 0.0005689576695493855, 0.0014792899408284023, 0.003846153846153846, 0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.44it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 31.69it/s]\n",
      "  1%|          | 1/191 [00:00<00:33,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000 | Loss: 4.65695 | Tr_c: 0.23181 | Vl_c: 0.25632 | Time: 0.402 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.16it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 29.46it/s]\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | Loss: 4.32163 | Tr_c: 0.25369 | Vl_c: 0.26981 | Time: 0.411 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.42it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 30.70it/s]\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002 | Loss: 4.26534 | Tr_c: 0.25746 | Vl_c: 0.26861 | Time: 0.412 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.41it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 31.08it/s]\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003 | Loss: 4.22254 | Tr_c: 0.26136 | Vl_c: 0.27281 | Time: 0.413 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.48it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 31.72it/s]\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004 | Loss: 4.19606 | Tr_c: 0.26315 | Vl_c: 0.27462 | Time: 0.416 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.42it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 32.85it/s]\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005 | Loss: 4.17579 | Tr_c: 0.26481 | Vl_c: 0.27273 | Time: 0.409 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.64it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 31.68it/s]\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006 | Loss: 4.15795 | Tr_c: 0.26675 | Vl_c: 0.27773 | Time: 0.417 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:25<00:00,  7.48it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 31.02it/s]\n",
      "  1%|          | 1/191 [00:00<00:34,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007 | Loss: 4.14211 | Tr_c: 0.26725 | Vl_c: 0.27645 | Time: 0.425 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:25<00:00,  7.27it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 32.26it/s]\n",
      "  1%|          | 1/191 [00:00<00:34,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008 | Loss: 4.12917 | Tr_c: 0.26831 | Vl_c: 0.27722 | Time: 0.419 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.39it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 30.28it/s]\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009 | Loss: 4.11439 | Tr_c: 0.27059 | Vl_c: 0.27783 | Time: 0.417 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:25<00:00,  7.43it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 30.82it/s]\n",
      "  1%|          | 1/191 [00:00<00:34,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010 | Loss: 4.10312 | Tr_c: 0.27109 | Vl_c: 0.28010 | Time: 0.417 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.48it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 32.57it/s]\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011 | Loss: 4.09774 | Tr_c: 0.27156 | Vl_c: 0.27777 | Time: 0.415 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:25<00:00,  7.57it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 32.85it/s]\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012 | Loss: 4.09179 | Tr_c: 0.27249 | Vl_c: 0.27925 | Time: 0.420 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.85it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 29.64it/s]\n",
      "  0%|          | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013 | Loss: 4.08530 | Tr_c: 0.27364 | Vl_c: 0.28165 | Time: 0.416 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:24<00:00,  7.15it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 30.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014 | Loss: 4.08118 | Tr_c: 0.27348 | Vl_c: 0.28220 | Time: 0.416 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Now unfreeze all layers and apply discr\n",
    "for grp in opt.param_groups:\n",
    "    grp['lr'] = bestlr\n",
    "\n",
    "lr_dscr = lambda opt, lr, fctr=2.6: [lr / (fctr ** i) for i in range(len(opt.param_groups))[::-1]]\n",
    "update_lr(opt, lr_dscr(opt, bestlr))\n",
    "\n",
    "if DEBUG:\n",
    "    print([x['lr'] for x in opt.param_groups])\n",
    "\n",
    "lr_args = {'iterations': len(data_fn(data_a=data_wiki['train'], data_b=data_imdb['train']))*15, 'cut_frac': 0.1, 'ratio': 32}\n",
    "lr_schedule = mtlr.LearningRateScheduler(opt, lr_args, mtlr.SlantedTriangularLR)\n",
    "args['lr_schedule'] = lr_schedule\n",
    "args['epochs'] = 15\n",
    "\n",
    "traces_main = generic_loop(**args)\n",
    "traces = [a+b for a, b in zip(traces_start, traces_main)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the traces\n",
    "with open(PATH/'unsup_dann_traces.pkl', 'wb+') as fl:\n",
    "    pickle.dump(traces, fl)\n",
    "\n",
    "pickle.dump(itos, open(DATA_LM_PATH / 'tmp' / 'itos_dann.pkl', 'wb'))\n",
    "torch.save(lm.state_dict(), PATH / 'unsup_dann_model.torch')\n",
    "torch.save(lm.encoder.state_dict(), PATH / 'unsup_dann_model_enc.torch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
