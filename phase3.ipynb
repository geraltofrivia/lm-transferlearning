{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from IPython.core.interactiveshell import InteractiveShell\n\n# pretty print all cell\u0027s output and not just the last one\nInteractiveShell.ast_node_interactivity \u003d \"all\"",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n# External Lib imports\nimport os\nfrom functools import partial\nfrom sklearn.utils import class_weight\nfrom typing import List, Union, Callable\n\nos.environ[\u0027QT_QPA_PLATFORM\u0027] \u003d \u0027offscreen\u0027\n\n# FastAI Imports\nfrom fastai import text, lm_rnn\n\n# Torch imports\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Mytorch imports\nfrom mytorch.utils.goodies import *\nfrom mytorch import loops, lriters as mtlr\n\n# Local imports\nimport main as p2\nimport utils\nfrom data import DataPuller\nfrom options import Phase3 as params, Phase2 as p2params\n\nPATH \u003d Path(\u0027resources/proc/imdb\u0027)\nDUMPPATH \u003d Path(\u0027resources/models/runs\u0027)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "QUICK \u003d False\nDEBUG \u003d True\nMODEL_NUM \u003d 0\nPRETRAINED \u003d True\nMODEL_SUFFIX \u003d \u0027\u0027\nSAFE_MODE \u003d False\nMESSAGE \u003d \u0027What have you?\u0027\nDATASETS \u003d \u0027imdb,trec\u0027.split(\u0027,\u0027)\nMODEL_DIR \u003d None\nLOSS_SCALE \u003d 6.0\nZERO \u003d None\n\nif MODEL_DIR is None:\n    UNSUP_MODEL_DIR \u003d DUMPPATH / \u0027_\u0027.join(DATASETS) / str(MODEL_NUM)\nelse:\n    UNSUP_MODEL_DIR \u003d DUMPPATH / MODEL_DIR / str(MODEL_NUM)\n    \nassert set(DATASETS).issuperset(\n    set(ZERO)), f\u0027At least one of the dataset which you instructed to ignore: {ZERO} is not being considered: {DATASETS}\u0027\n\nZERO \u003d [DATASETS.index(d) for d in ZERO]\nif ZERO \u003d\u003d 0:\n    # If the task which we want to leave untrained in task 0,\n    alter_task \u003d 1\nelse:\n    alter_task \u003d 0\nZERO_TASK_INDEX \u003d {ZERO[0]: alter_task}\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "device \u003d torch.device(\u0027cuda\u0027)\nnp.random.seed(42)\ntorch.manual_seed(42)\n\n\u0027\u0027\u0027\n    Paths and macros\n\u0027\u0027\u0027\nPATH \u003d Path(\u0027resources/proc/imdb\u0027)\nDATA_PROC_PATH \u003d PATH / \u0027data\u0027\nDATA_LM_PATH \u003d PATH / \u0027datalm\u0027\n\nLM_PATH \u003d Path(\u0027resources/models\u0027)\nLM_PATH.mkdir(exist_ok\u003dTrue)\nPRE_PATH \u003d LM_PATH / \u0027wt103\u0027\nPRE_LM_PATH \u003d PRE_PATH / \u0027fwd_wt103.h5\u0027\nKNOWN_DATASETS \u003d {\u0027imdb\u0027: 2, \u0027trec\u0027: 6, \u0027cornell\u0027: 2}\n\n\n\u0027\u0027\u0027\n    Models, Data Samplers etc\n\u0027\u0027\u0027\n\n\nclass FakeBatchNorm1d(nn.Module):\n    \"\"\"\n        Class which keeps its interface same b/w batchnorm1d and doesn\u0027t do shit.\n        Needed for when I send sliced encoded tensors to classifier to perform pointwise classification.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return x\n\n\nclass CustomLinearBlock(text.LinearBlock):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.bn \u003d FakeBatchNorm1d()\n\n\nclass CustomPoolingLinearClassifier(text.PoolingLinearClassifier):\n    \"\"\" Overwriting lm_rnn\u0027s PoolingLinearClassifier so it uses CustomLinearBlock (with no batchnorm)\"\"\"\n    def __init__(self, layers, drops):\n        super().__init__(layers, drops)\n        self.layers \u003d nn.ModuleList([\n            CustomLinearBlock(layers[i], layers[i + 1], drops[i]) for i in range(len(layers) - 1)])\n\n\nclass CustomEncoder(lm_rnn.MultiBatchRNN):\n    @property\n    def layers(self):\n        return torch.nn.ModuleList([\n            torch.nn.ModuleList([self.encoder, self.encoder_with_dropout]),\n            torch.nn.ModuleList([self.rnns[0], self.dropouths[0]]),\n            torch.nn.ModuleList([self.rnns[1], self.dropouths[1]]),\n            torch.nn.ModuleList([self.rnns[2], self.dropouths[2]])\n        ])\n\n\nclass TextClassifier(nn.Module):\n\n    # @TODO: inject comments.\n    def __init__(self,\n                 _device: torch.device,\n                 n_token: int,\n                 dps: list,\n                 n_classes: List[int],\n                 enc_wgts \u003d None,\n                 _debug\u003dFalse):\n        super(TextClassifier, self).__init__()\n        \"\"\"\n        :param n_token: int representing vocab size\n        :param n_classes: list representing multiple classes, each by its number of classes.\n            eg. n_classes \u003d [2] -\u003e one task; with 2 classes\n            eg. n_classes \u003d [2, 6] -\u003e two tasks, first with 2 classes, and one with 6.\n        \"\"\"\n\n        self.device \u003d _device\n\n        # Load the pre-trained model\n        encargs \u003d {\u0027ntoken\u0027: n_token, \u0027emb_sz\u0027: 400, \u0027n_hid\u0027: 1150,\n                   \u0027n_layers\u0027: 3, \u0027pad_token\u0027: 0, \u0027qrnn\u0027: False, \u0027bptt\u0027: 70, \u0027max_seq\u0027: 1400,\n                   \u0027dropouti\u0027: dps[0], \u0027wdrop\u0027: dps[1], \u0027dropoute\u0027: dps[2], \u0027dropouth\u0027: dps[3]}\n        self.encoder \u003d CustomEncoder(**encargs).to(self.device)\n\n        if enc_wgts:\n            self.encoder.load_state_dict(enc_wgts)\n\n        \u0027\u0027\u0027\n            Make multiple classifiers (depending upon n_classes)\n            \n            \n            Explanation:\n                400*3 because input is [ h_T, maxpool, meanpool ]\n                50 is hidden layer dim\n                2 is n_classes\n\n                0.4, 0.1 are drops at various layers\n        \u0027\u0027\u0027\n        self.linear \u003d torch.nn.ModuleList([CustomPoolingLinearClassifier(layers\u003d[400 * 3, 50, cls], drops\u003d[dps[4], 0.1]).to(self.device)\n                       for cls in n_classes])\n        self.domain_clf \u003d p2.CustomLinear(layers\u003dp2params.domclas_layers + [len(n_classes)], drops\u003dp2params.domclas_drops).to(self.device)\n        self.encoder.reset()\n\n    @property\n    def layers(self):\n        layers \u003d [x for x in self.encoder.layers]\n        len_layers \u003d [len(lin.layers) for lin in self.linear] + [len(self.domain_clf.layers)]\n        srcs \u003d [lin for lin in self.linear] + [self.domain_clf]\n        for i in range(max(len_layers)):\n            tmp_layers \u003d []\n            for src in range(len(srcs)):\n                if len_layers[src] !\u003d 0:\n                    tmp_layers.append(srcs[src].layers[i])\n                    len_layers[src] -\u003d 1\n            layers.append(torch.nn.ModuleList(tmp_layers))\n\n        return torch.nn.ModuleList(layers)\n\n    def forward(self, x: torch.tensor, domain: torch.tensor, task_index: dict \u003d None):\n        \"\"\" x is bs, sl; dom is bs indicating the task.\n                task index can reroute tasks of a domain to another.\n                Eg. if task_index \u003d {1:0}, all those tasks which are of domain[i] \u003d 1, will not be done with linear[1] but with linear[0]\n        \"\"\"\n\n        if task_index is None:\n            task_index \u003d {}\n\n        # Encoding all the data\n        x_proc \u003d self.encoder(x.transpose(1, 0))\n\n        sl, bs, _ \u003d x_proc[0][0].shape\n\n        score \u003d []\n        for pos, dom in enumerate(domain):\n            \"\"\"\n                Right now, x_proc looks like ( [(sl, bs, hdim)*n_layers_enc], [(sl, bs, hdim)*n_layers_enc)] \n                    for dropped and non dropped outputs respectively.\n                \n                Depending on {dom.item()}^th task on {i}^th position,\n                We slice from x_proc a tensor of (sl, 1, hdim) shape based on i, and feed it to the {dom}\u0027th decoder.\n            \n                Finally, we concat the outputs in a nice little list and pretend nothing happened [:\n                \n                NOTE: This shit might be slow                     \n            \"\"\"\n            x_proc_pos \u003d ([layer_op[:, pos].view(sl, 1, -1) for layer_op in x_proc[0]],\n                         [layer_op[:, pos].view(sl, 1, -1) for layer_op in x_proc[1]])\n            score.append(self.linear[dom.item() if dom.item() not in task_index else task_index[dom.item()]](x_proc_pos)[0])\n\n        return score, x_proc\n\n    def domain(self, x_proc):\n        # @TODO: FIX\n        # print(x_proc)\n        x_proc \u003d list(x_proc)\n        x_proc[1] \u003d [GradReverse.apply(enc_tensr) for enc_tensr in x_proc[1]]\n        return self.domain_clf(x_proc)[0]\n\n    def predict(self, x, d, task_index: None):\n        with torch.no_grad():\n            self.eval()\n            predicted \u003d self.forward(x, d, task_index)\n            self.train()\n            return predicted\n\ndef epoch_end_hook(lr_schedule: mtlr.LearningRateScheduler) -\u003e None:\n    \"\"\"\n        Calling the lr schedule to unfreeze one layer and unfreezing one layer.\n        \n    :param lr_schedule: the schedule we want to reset.\n    :return: Nada\n    \"\"\"\n\n    lr_schedule.unfreeze()\n    lr_schedule.reset()\n\n\ndef custom_argmax(x: List[torch.Tensor], dim: int \u003d 1) -\u003e torch.Tensor:\n    \"\"\" Expects a list of tensors, and computes individual\u0027s argmax\"\"\"\n    return torch.cat([pred.argmax(dim\u003ddim) for pred in x])\n\n\n# noinspection PyUnresolvedReferences\ndef _list_eval(y_pred: list, y_true: torch.Tensor, tasks: int \u003d 1, task_index: torch.Tensor \u003d None) -\u003e List[np.float]:\n    \"\"\"\n        Expects y_pred to be a list of tensors, but y_true to be a one tensor.\n        Also takes tasks as inputs and another tensor which specifies which example belongs to which task\n\n        Returns a list of floats (one for each task. Minimum: 1)\n\n        :param y_pred: list of n_batches items each of shape (1, nc_t) where nc_t can have multiple values\n        :param y_true: tensor of shape (b, 1)\n        :param tasks: (int, optional) a number of unique tasks for which we report eval\n        :param task_index: (torch.Tensor, optional) a vector indicating which tasks\n    \"\"\"\n    acc \u003d (custom_argmax(y_pred, dim\u003d1) \u003d\u003d y_true).float()\n    if not tasks \u003e 1 or task_index is None:\n        return torch.mean(acc).item()\n\n    return [torch.mean(torch.masked_select(acc, task_index \u003d\u003d task)).item() for task in range(tasks)]\n\n\n# noinspection PyUnresolvedReferences\ndef _eval(y_pred, y_true, **args):\n    \"\"\"\n        Expects a batch of input\n\n        Ignores a bunch of extra args.\n\n        :param y_pred: tensor of shape (b, nc)\n        :param y_true: tensor of shape (b, 1)\n    \"\"\"\n    # print(y_pred[0])\n    return torch.mean((torch.argmax(y_pred, dim\u003d1) \u003d\u003d y_true).float())\n\n\n## noinspection PyUnresolvedReferences\ndef multitask_classification_loss(y_pred: list, y_true: torch.Tensor, loss_fn: List[Union[torch.nn.Module, Callable]],\n                                  task_index: torch.Tensor \u003d None, ignore_dataset: list \u003d [], **args) -\u003e torch.Tensor:\n    \"\"\"\n        Accepts different sized y_preds where each element can have [1, _] shapes.\n        Provide one or multiple loss functions depending upon the num of tasks, using our regular -partial- thing.\n\n        Eg. lfn \u003d partial(multitask_classification_loss, loss_fn:torch.nn.CrossEntropyLoss())\n\n    :param y_pred: (list) of tensors where each tensor is of shape (1, _) of length bs\n    :param y_true: (torch.Tensor) of shape (bs,)\n    :param loss_fn: (torch.nn.Module or a function; or a list of those) which calculate the loss given a y_true and y_pred.\n    :param task_index: (torch.Tensor, Optional) of shape (bs,) which dictates which loss to use.\n                       Must be provided if there are multiple loss_fns provided\n    :param ignore_dataset: (list of ints) indicating which task_index values to ignore. \n            Eg. if task_index[0] -\u003e 1 implies that its from \u0027imdb\u0027 task, and you won\u0027t wanna train on it, simply pass [1] as ignore_dataset\n    :return: the loss value (torch.Tensor)\n    \"\"\"\n\n    # Case 1, only one task -\u003e len(loss_fn) \u003d\u003d 1. Ignore task index, in this case\n    if len(loss_fn) \u003d\u003d 1:\n        losses \u003d torch.cat([loss_fn[0](_y_pred.view(1, -1), y_true[i].unsqueeze(0)).view(-1)\n                  for i, _y_pred in enumerate(y_pred)])\n\n    else:\n        # Case 2: multiple loss functions. In that case, choose the loss fn based on task index\n        assert len(y_pred) \u003d\u003d y_true.shape[0] \u003d\u003d task_index.shape[0], f\"Mismatch between y_pred of {len(y_pred)} items, \" \\\n            f\"y_true of len {y_true.shape[0]}, and task_index of len {task_index.shape[0]}\"\n\n        losses \u003d [loss_fn[task_index[i].item()](_y_pred.view(1, -1), y_true[i].unsqueeze(0)).view(-1)\n                  for i, _y_pred in enumerate(y_pred) if task_index[i].item() not in ignore_dataset]\n        \n        \n        if len(losses) \u003d\u003d 0:\n            # Edge case: all the entries are to be ignored\n            losses \u003d torch.tensor(0, device\u003dtask_index.device, dtype\u003dtorch.float)\n        else: \n            losses \u003d torch.cat(losses)\n        \n    return torch.sum(losses)\n\n\ndef domain_classifier_loss(y_pred: list, y_true: torch.Tensor, loss_fn: List[Union[torch.nn.Module, Callable]], **args):\n    \"\"\" Thin wrapper over loss fn to accept misguided args.\"\"\"\n    return loss_fn(y_pred, y_true)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "assert MODEL_SUFFIX in [\u0027_lowaux\u0027, \u0027_hightrn\u0027, \u0027\u0027, \u0027_final\u0027], \u0027Incorrect Suffix given with which to load model\u0027\n\nparams.quick \u003d QUICK\nparams.model_dir \u003d str(UNSUP_MODEL_DIR) + \u0027 and \u0027 + str(MODEL_NUM)\nparams.model_suffix \u003d MODEL_SUFFIX\nparams.datasets \u003d DATASETS\nif LOSS_SCALE is not None:\n    params.loss_scale \u003d LOSS_SCALE\n\n# Create representations of text using old itos\nitos_path \u003d UNSUP_MODEL_DIR / \u0027itos.pkl\u0027\nitos2 \u003d pickle.load(itos_path.open(\u0027rb\u0027))\nstoi2 \u003d {v: k for k, v in enumerate(itos2)}\n\ndata_puller \u003d DataPuller(debug\u003dFalse, max_vocab\u003dparams.max_vocab_task, min_freq\u003dparams.min_vocab_freq,\n                         trim_trn\u003d1000, trim_val\u003d1000)\n\ntrn_texts, trn_labels, val_texts, val_labels, task_specific_weights \u003d [], [], [], [], []\nfor dataset in DATASETS:\n\n    trn_texts_, trn_labels_, val_texts_, val_labels_, itos \u003d data_puller.get(dataset, supervised\u003dTrue,\n                                                                             merge_vocab\u003dparams.max_vocab_others,\n                                                                             trim\u003dparams.quick, cached\u003dTrue)\n\n    # Lose label 2 from imdb\n    if dataset \u003d\u003d \u0027imdb\u0027:\n        trn_texts_ \u003d trn_texts_[trn_labels_ \u003c 2]\n        trn_labels_ \u003d trn_labels_[trn_labels_ \u003c 2]\n\n    # Compute weights for cross entropy loss\n    class_weights_ \u003d class_weight.compute_class_weight(\u0027balanced\u0027, classes\u003drange(KNOWN_DATASETS[dataset]), y\u003dtrn_labels_)\n\n    # Store all things in a nice format\n    trn_texts.append(trn_texts_)\n    trn_labels.append(trn_labels_)\n    val_texts.append(val_texts_)\n    val_labels.append(val_labels_)\n    task_specific_weights.append(class_weights_)\n\n# At this point, the five lists contain each some aspect of our datasets. itos (the list overwritten in the loop) contains the vocab.\n\n# Transform words from data_puller.itos vocabulary to that of the pretrained model (__main__.itos2)\n_itos2 \u003d dict(enumerate(itos2))\nfor i, (trn_texts_, val_texts_) in enumerate(zip(trn_texts, val_texts)):\n    trn_texts[i] \u003d [[stoi2[_itos2.get(i, \u0027_unk_\u0027)] for i in sent] for sent in trn_texts_]\n    val_texts[i] \u003d [[stoi2[_itos2.get(i, \u0027_unk_\u0027)] for i in sent] for sent in val_texts_]\n\n# Compute dataset specific weights. Formula: n_samples / (n_classes * np.bincount(\u003cflatlist_indexing_all_samples_for_all_datasets\u003e))\nbincount \u003d np.array([len(trn_labels_) for trn_labels_ in trn_labels])\ndataset_specific_weights \u003d np.sum(bincount) / (len(bincount) * bincount)\n\n\n\u0027\u0027\u0027\n    Make model\n\u0027\u0027\u0027\ndps \u003d list(params.encoder_dropouts)\nenc_wgts \u003d torch.load(UNSUP_MODEL_DIR / (\u0027unsup_model_enc\u0027 + MODEL_SUFFIX + \u0027.torch\u0027), map_location\u003dlambda storage, loc: storage)\nn_classes \u003d [KNOWN_DATASETS[d] for d in DATASETS]\nclf \u003d TextClassifier(device, len(itos2), dps, enc_wgts\u003denc_wgts if PRETRAINED else None, n_classes\u003dn_classes)\n\n\u0027\u0027\u0027\n    Setup things for training (data, loss, opt, lr schedule etc\n\u0027\u0027\u0027\nbs \u003d params.bs\nloss_fns \u003d [torch.nn.CrossEntropyLoss(weight\u003dtorch.tensor(w, device\u003ddevice, dtype\u003dtorch.float))\n            for w in task_specific_weights]\nloss_main_fn \u003d partial(multitask_classification_loss, loss_fn\u003dloss_fns, ignore_dataset\u003dZERO)\nif len(DATASETS) \u003e 1:\n    loss_aux_fn \u003d partial(domain_classifier_loss, loss_fn\u003dtorch.nn.CrossEntropyLoss(\n        torch.tensor(dataset_specific_weights, device\u003ddevice, dtype\u003dtorch.float)))\nelse:\n    # Weights dont make sense if only one domain is being worked with\n    loss_aux_fn \u003d partial(domain_classifier_loss, loss_fn\u003dtorch.nn.CrossEntropyLoss())\nopt_fn \u003d partial(optim.Adam, betas\u003dparams.adam_betas)\nopt \u003d make_opt(clf, opt_fn, lr\u003dparams.lr.init)\n\n# Make data\ndata_fn \u003d partial(utils.DomainAgnosticSortishSampler, _batchsize\u003dbs, _padidx\u003d1)\ndata_train \u003d [{\u0027x\u0027: trn_texts_, \u0027y\u0027: trn_labels_} for trn_texts_, trn_labels_ in zip(trn_texts, trn_labels)]\ndata_valid \u003d [{\u0027x\u0027: val_texts_, \u0027y\u0027: val_labels_} for val_texts_, val_labels_ in zip(val_texts, val_labels)]\ndata \u003d {\u0027train\u0027: data_train, \u0027valid\u0027: data_valid}\n\n# Make lr scheduler\norg_iterations \u003d len(data_fn(data_train))\nfreeze_mask \u003d  np.array([0 for _ in opt.param_groups])\nfreeze_mask[-1] \u003d 1\nlr_args \u003d {\u0027iterations\u0027: org_iterations, \u0027cycles\u0027: 1}\nlr_schedule \u003d mtlr.LearningRateScheduler(optimizer\u003dopt, lr_args\u003dlr_args, lr_iterator\u003dmtlr.CosineAnnealingLR, freeze_mask\u003dfreeze_mask)\n\nsave_args \u003d {\u0027torch_stuff\u0027: [tosave(\u0027model.torch\u0027, clf.state_dict()), tosave(\u0027model_enc.torch\u0027, clf.encoder.state_dict())]}\nsave_fnames \u003d {\u0027torch_stuff\u0027:\n                   {\u0027hightrn\u0027:\n                        {\u0027model\u0027: \u0027sup_model_hightrn.torch\u0027,\n                         \u0027enc\u0027: \u0027sup_model_hightrn_enc.torch\u0027},\n                    \u0027lowaux\u0027:\n                        {\u0027model\u0027: \u0027sup_model_lowaux.torch\u0027,\n                         \u0027enc\u0027: \u0027sup_model_lowaux_enc.torch\u0027}}}\n\nargs \u003d {\u0027epochs\u0027: 1, \u0027epoch_count\u0027: 0, \u0027data\u0027: data, \u0027device\u0027: device, \u0027opt\u0027: opt,\n        \u0027loss_main_fn\u0027: loss_main_fn, \u0027loss_aux_fn\u0027: loss_aux_fn, \u0027model\u0027: clf,\n        \u0027train_fn\u0027: clf, \u0027predict_fn\u0027: partial(clf.predict, task_index\u003dZERO_TASK_INDEX), \u0027train_aux_fn\u0027: clf.domain,\n        \u0027epoch_end_hook\u0027: partial(epoch_end_hook, lr_schedule\u003dlr_schedule),\n        \u0027weight_decay\u0027: params.weight_decay, \u0027clip_grads_at\u0027: params.clip_grads_at, \u0027lr_schedule\u0027: lr_schedule,\n        \u0027loss_aux_scale\u0027: params.loss_scale if len(DATASETS) \u003e 1 else 0, \u0027tasks\u0027: len(DATASETS),\n        \u0027data_fn\u0027: data_fn, \u0027eval_fn\u0027: _list_eval, \u0027eval_aux_fn\u0027: _eval,\n        \u0027save\u0027: not SAFE_MODE, \u0027save_params\u0027: params, \u0027save_dir\u0027: UNSUP_MODEL_DIR, \u0027save_fnames\u0027: save_fnames}\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\u0027\u0027\u0027\n    Training schedule:\n    NOTE: removed all freezing\n    \n    1. Unfreeze one layer. Train for 1 epoch\n    2 - 5. Unfreeze one layer, train for 1 epoch\n    3. Train for 15 epochs (after all layers are unfrozen). Use 15 cycles for cosine annealing.\n    \n    @TODO: save_above_trn, save_below_aux needs to be fixed to handle multiple values!!\n\u0027\u0027\u0027\n# Freeze all layers\ntraces \u003d utils.dann_loop(**args)\n\nargs[\u0027save_above_trn\u0027] \u003d np.max(traces[utils.TRACES_FORMAT[\u0027train_acc_main\u0027]])\nargs[\u0027epoch_count\u0027] +\u003d 1\ntraces_new \u003d utils.dann_loop(**args)\ntraces \u003d [a+b for a, b in zip(traces, traces_new)]\n\nargs[\u0027save_above_trn\u0027] \u003d np.max(traces[utils.TRACES_FORMAT[\u0027train_acc_main\u0027]])\nargs[\u0027epoch_count\u0027] +\u003d 1\ntraces_new \u003d utils.dann_loop(**args)\ntraces \u003d [a+b for a, b in zip(traces, traces_new)]\n\nargs[\u0027save_above_trn\u0027] \u003d np.max(traces[utils.TRACES_FORMAT[\u0027train_acc_main\u0027]])\nargs[\u0027save_above_aux\u0027] \u003d np.min(traces[utils.TRACES_FORMAT[\u0027train_acc_aux\u0027]][2:])\nargs[\u0027epoch_count\u0027] +\u003d 1\ntraces_new \u003d utils.dann_loop(**args)\ntraces \u003d [a+b for a, b in zip(traces, traces_new)]\n\nargs[\u0027save_above_trn\u0027] \u003d np.max(traces[utils.TRACES_FORMAT[\u0027train_acc_main\u0027]])\nargs[\u0027save_above_aux\u0027] \u003d np.min(traces[utils.TRACES_FORMAT[\u0027train_acc_aux\u0027]][2:])\nargs[\u0027epoch_count\u0027] +\u003d 1\ntraces_new \u003d utils.dann_loop(**args)\ntraces \u003d [a+b for a, b in zip(traces, traces_new)]\n\nargs[\u0027epochs\u0027] \u003d 15\nargs[\u0027save_above_trn\u0027] \u003d np.max(traces[utils.TRACES_FORMAT[\u0027train_acc_main\u0027]])\nargs[\u0027save_above_aux\u0027] \u003d np.min(traces[utils.TRACES_FORMAT[\u0027train_acc_aux\u0027]][2:])\nargs[\u0027epoch_count\u0027] +\u003d 1\nargs[\u0027notify\u0027] \u003d True\n\ntraces_new \u003d utils.dann_loop(**args)\ntraces \u003d [a+b for a, b in zip(traces, traces_new)]\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "if not SAFE_MODE:\n    mt_save(UNSUP_MODEL_DIR, message\u003dMESSAGE, message_fname\u003d\"message_p3.txt\",\n            torch_stuff\u003d[tosave(\u0027sup_model_final.torch\u0027, clf.state_dict())],\n            pickle_stuff\u003d[tosave(\u0027final_sup_traces.pkl\u0027, traces), tosave(\u0027unsup_options.pkl\u0027, params)])",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "UNSUP_MODEL_DIR",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "raw",
      "source": "from matplotlib import pyplot as plt\ndef plot(trcs):\n    layers \u003d len(trcs[0])\n    for l in range(layers):\n        plt.plot(trcs[:,l], label\u003df\"layer {l}\")\n    plt.show()\n    \nplot(np.asarray(traces[-1][100:]))\nplot(np.asarray([[x[-1]] for x in traces[-1][:]]))\n\nprint(lr_args)\nlr_args[\u0027cycles\u0027] \u003d 5\nlr_args[\u0027iterations\u0027] \u003d 42*15\nlr_schedule \u003d mtlr.LearningRateScheduler(optimizer\u003dopt, lr_args\u003dlr_args, lr_iterator\u003dmtlr.CosineAnnealingLR)\nlrs \u003d []\nwhile True:\n    try:\n        lrs.append(lr_schedule.get())\n    except CustomError:\n        break\nplot(np.asarray(lrs))",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from matplotlib import pyplot as plt\nfrom matplotlib import style as pltstyle\n%pylab inline\n\n# Plot learning rates\ndef plot_lrs(trcs):\n    layers \u003d len(trcs[0])\n    trcs \u003d np.array(trcs)\n    fig \u003d plt.figure(figsize \u003d (16,8))\n    for l in range(layers):\n        plt.plot(trcs[:,l], label\u003df\"layer {l}\")\n    plt.show()\n\ndef plot_accs(tra, vla, style\u003dNone, save_dir\u003dNone):\n    pltstyle.use(style if style else \u0027seaborn-deep\u0027)\n    fig \u003d plt.figure(figsize \u003d (16,8))\n    ax \u003d fig.add_axes((0.1, 0.2, 0.8, 0.7))\n    ax.spines[\u0027right\u0027].set_color(\u0027none\u0027)\n    ax.spines[\u0027top\u0027].set_color(\u0027none\u0027)\n#     plt.xticks([])\n#     plt.yticks([])\n    ax.plot(tra, label\u003df\"Train Acc\", linewidth\u003d3)\n    ax.plot(vla, label\u003df\"Valid Acc\", linewidth\u003d3)\n    ax.set_ylim(bottom\u003d0)\n    ax.legend()\n    plt.show()\n    \n    if not save_dir is None:\n        # Dumping the plot as well\n        pltstyle.use(style if style else \u0027seaborn-deep\u0027)\n        fig \u003d plt.figure(figsize \u003d (16,8))\n        ax \u003d fig.add_axes((0.1, 0.2, 0.8, 0.7))\n        ax.spines[\u0027right\u0027].set_color(\u0027none\u0027)\n        ax.spines[\u0027top\u0027].set_color(\u0027none\u0027)\n    #     plt.xticks([])\n    #     plt.yticks([])\n        ax.plot(tra, label\u003df\"Train Acc\", linewidth\u003d3)\n        ax.plot(vla, label\u003df\"Valid Acc\", linewidth\u003d3)\n        ax.set_ylim(bottom\u003d0)\n        ax.legend()\n        plt.savefig(save_dir/\u0027sup_acc.png\u0027)\n    \ndef plot(trcs):\n    layers \u003d len(trcs[0])\n    for l in range(layers):\n        plt.plot(trcs[:,l], label\u003df\"layer {l}\")\n    plt.show()\n    \nplot_accs(traces[0], traces[1], save_dir\u003dUNSUP_MODEL_DIR if not SAFE_MODE else None)\nplot_lrs(traces[utils.TRACES_FORMAT[\u0027lrs\u0027]])",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def understand_traces(traces):\n    # Simply find places where each of trn acc is highest\n    trn_ids \u003d np.argmax(np.array(traces[utils.TRACES_FORMAT[\u0027train_acc_main\u0027]]), axis\u003d0)\n    ids \u003d list(np.unique(trn_ids))\n\n    # Find where vals is highest\n    val_ids \u003d np.argmax(np.array(traces[utils.TRACES_FORMAT[\u0027val_acc\u0027]]), axis\u003d0)\n    ids.extend(list(np.unique(val_ids)))\n\n    # Find where dom is lowest\n    dom_ids \u003d np.argmin(np.array(traces[utils.TRACES_FORMAT[\u0027train_acc_aux\u0027]][3:]), axis\u003d0) + 3\n    ids.extend(list(np.unique(dom_ids)))\n\n    _ids \u003d ids[0]\n    # Now to print these things\n    for _ids in ids:\n        print(f\u0027@{_ids:3d}: \u0027,\n              np.around(traces[utils.TRACES_FORMAT[\u0027train_acc_main\u0027]][_ids], decimals\u003d4),\n              \u0027|\u0027, np.around(traces[utils.TRACES_FORMAT[\u0027val_acc\u0027]][_ids], decimals\u003d4),\n              \u0027|\u0027, np.around(traces[utils.TRACES_FORMAT[\u0027train_acc_aux\u0027]][_ids], decimals\u003d4))\n        \n        \nunderstand_traces(traces)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "pycharm-c18a23a2",
      "language": "python",
      "display_name": "PyCharm (lm-transferlearning)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}